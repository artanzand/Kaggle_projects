{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and building a simple ML pipeline\n",
    "\n",
    "A crucial step when using machine learning algorithms on real-world datasets is preprocessing. In this notebook I will do a demo of data preprocessing and building a simple supervised machine learning pipeline on a real-world dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.enable('data_server')\n",
    "alt.renderers.enable(\"mimetype\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: The dataset \n",
    "<hr>\n",
    "\n",
    "In this exercise I will be working on [the adult census dataset](https://www.kaggle.com/uciml/adult-census-income#). This is a classification dataset and the classification task is to predict whether income exceeds 50K per year or not based on the census data. More information on the dataset and features can be found [here](http://archive.ics.uci.edu/ml/datasets/Adult).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_df = pd.read_csv(\"../downloads/adult.csv\")\n",
    "census_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data splitting \n",
    "\n",
    "In order to avoid violation of the golden rule, the first step before we do anything is splitting the data. Usually having more data for training is a good idea. But here I'm using 60%/40% split because this is kind of a big dataset for a modest laptop. A side advantage of this would be that with a bigger test split, we'll have a more reliable estimate of the deployment performance!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(census_df, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2: Exploratory data analysis (EDA)  \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine our `train_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>216864</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>70037</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>3004</td>\n",
       "      <td>60</td>\n",
       "      <td>?</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32553</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>84661</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32554</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>116138</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>321865</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19536 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt     education  education.num      marital.status  \\\n",
       "0       90         ?   77053       HS-grad              9             Widowed   \n",
       "1       82   Private  132870       HS-grad              9             Widowed   \n",
       "2       66         ?  186061  Some-college             10             Widowed   \n",
       "5       34   Private  216864       HS-grad              9            Divorced   \n",
       "9       41   Private   70037  Some-college             10       Never-married   \n",
       "...    ...       ...     ...           ...            ...                 ...   \n",
       "32553   43   Private   84661     Assoc-voc             11  Married-civ-spouse   \n",
       "32554   32   Private  116138       Masters             14       Never-married   \n",
       "32555   53   Private  321865       Masters             14  Married-civ-spouse   \n",
       "32557   27   Private  257302    Assoc-acdm             12  Married-civ-spouse   \n",
       "32559   58   Private  151910       HS-grad              9             Widowed   \n",
       "\n",
       "            occupation   relationship                race     sex  \\\n",
       "0                    ?  Not-in-family               White  Female   \n",
       "1      Exec-managerial  Not-in-family               White  Female   \n",
       "2                    ?      Unmarried               Black  Female   \n",
       "5        Other-service      Unmarried               White  Female   \n",
       "9         Craft-repair      Unmarried               White    Male   \n",
       "...                ...            ...                 ...     ...   \n",
       "32553            Sales        Husband               White    Male   \n",
       "32554     Tech-support  Not-in-family  Asian-Pac-Islander    Male   \n",
       "32555  Exec-managerial        Husband               White    Male   \n",
       "32557     Tech-support           Wife               White  Female   \n",
       "32559     Adm-clerical      Unmarried               White  Female   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0                 0          4356              40  United-States  <=50K  \n",
       "1                 0          4356              18  United-States  <=50K  \n",
       "2                 0          4356              40  United-States  <=50K  \n",
       "5                 0          3770              45  United-States  <=50K  \n",
       "9                 0          3004              60              ?   >50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32553             0             0              45  United-States  <=50K  \n",
       "32554             0             0              11         Taiwan  <=50K  \n",
       "32555             0             0              40  United-States   >50K  \n",
       "32557             0             0              38  United-States  <=50K  \n",
       "32559             0             0              40  United-States  <=50K  \n",
       "\n",
       "[19536 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some missing values represented with a \"?\". Usually `.describe()` or `.info()` methods would give you information on missing values. But here, they won't pick \"?\" as missing values as they are encoded as strings instead of an actual NaN in Python. So we'll replace them with `np.nan` before we carry out EDA. If you do not do it, you'll encounter an error later on when you try to pass this data to a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19536, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan = train_df.replace(\"?\", np.nan)\n",
    "test_df_nan = test_df.replace(\"?\", np.nan)\n",
    "train_df_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>216864</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>70037</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>3004</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32553</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>84661</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32554</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>116138</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>321865</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19536 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt     education  education.num      marital.status  \\\n",
       "0       90       NaN   77053       HS-grad              9             Widowed   \n",
       "1       82   Private  132870       HS-grad              9             Widowed   \n",
       "2       66       NaN  186061  Some-college             10             Widowed   \n",
       "5       34   Private  216864       HS-grad              9            Divorced   \n",
       "9       41   Private   70037  Some-college             10       Never-married   \n",
       "...    ...       ...     ...           ...            ...                 ...   \n",
       "32553   43   Private   84661     Assoc-voc             11  Married-civ-spouse   \n",
       "32554   32   Private  116138       Masters             14       Never-married   \n",
       "32555   53   Private  321865       Masters             14  Married-civ-spouse   \n",
       "32557   27   Private  257302    Assoc-acdm             12  Married-civ-spouse   \n",
       "32559   58   Private  151910       HS-grad              9             Widowed   \n",
       "\n",
       "            occupation   relationship                race     sex  \\\n",
       "0                  NaN  Not-in-family               White  Female   \n",
       "1      Exec-managerial  Not-in-family               White  Female   \n",
       "2                  NaN      Unmarried               Black  Female   \n",
       "5        Other-service      Unmarried               White  Female   \n",
       "9         Craft-repair      Unmarried               White    Male   \n",
       "...                ...            ...                 ...     ...   \n",
       "32553            Sales        Husband               White    Male   \n",
       "32554     Tech-support  Not-in-family  Asian-Pac-Islander    Male   \n",
       "32555  Exec-managerial        Husband               White    Male   \n",
       "32557     Tech-support           Wife               White  Female   \n",
       "32559     Adm-clerical      Unmarried               White  Female   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0                 0          4356              40  United-States  <=50K  \n",
       "1                 0          4356              18  United-States  <=50K  \n",
       "2                 0          4356              40  United-States  <=50K  \n",
       "5                 0          3770              45  United-States  <=50K  \n",
       "9                 0          3004              60            NaN   >50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32553             0             0              45  United-States  <=50K  \n",
       "32554             0             0              11         Taiwan  <=50K  \n",
       "32555             0             0              40  United-States   >50K  \n",
       "32557             0             0              38  United-States  <=50K  \n",
       "32559             0             0              40  United-States  <=50K  \n",
       "\n",
       "[19536 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualizing features\n",
    "\n",
    "We will visualize the histograms of numeric features. Alternatively, we could have used [`pandas_profiling`](https://github.com/pandas-profiling/pandas-profiling) for more elaborate visualization and EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19536 entries, 25823 to 23654\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             19536 non-null  int64 \n",
      " 1   workclass       18428 non-null  object\n",
      " 2   fnlwgt          19536 non-null  int64 \n",
      " 3   education       19536 non-null  object\n",
      " 4   education.num   19536 non-null  int64 \n",
      " 5   marital.status  19536 non-null  object\n",
      " 6   occupation      18424 non-null  object\n",
      " 7   relationship    19536 non-null  object\n",
      " 8   race            19536 non-null  object\n",
      " 9   sex             19536 non-null  object\n",
      " 10  capital.gain    19536 non-null  int64 \n",
      " 11  capital.loss    19536 non-null  int64 \n",
      " 12  hours.per.week  19536 non-null  int64 \n",
      " 13  native.country  19187 non-null  object\n",
      " 14  income          19536 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df_nan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19536.000000</td>\n",
       "      <td>1.953600e+04</td>\n",
       "      <td>19536.000000</td>\n",
       "      <td>19536.000000</td>\n",
       "      <td>19536.000000</td>\n",
       "      <td>19536.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.592547</td>\n",
       "      <td>1.892662e+05</td>\n",
       "      <td>10.084767</td>\n",
       "      <td>1090.443540</td>\n",
       "      <td>86.537162</td>\n",
       "      <td>40.532606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.638971</td>\n",
       "      <td>1.049020e+05</td>\n",
       "      <td>2.580723</td>\n",
       "      <td>7449.700833</td>\n",
       "      <td>402.395668</td>\n",
       "      <td>12.406636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.177670e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.782835e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.368860e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.455435e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "count  19536.000000  1.953600e+04   19536.000000  19536.000000  19536.000000   \n",
       "mean      38.592547  1.892662e+05      10.084767   1090.443540     86.537162   \n",
       "std       13.638971  1.049020e+05       2.580723   7449.700833    402.395668   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.177670e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.782835e+05      10.000000      0.000000      0.000000   \n",
       "75%       47.000000  2.368860e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.455435e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours.per.week  \n",
       "count    19536.000000  \n",
       "mean        40.532606  \n",
       "std         12.406636  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'age'}>,\n",
       "        <AxesSubplot:title={'center':'fnlwgt'}>],\n",
       "       [<AxesSubplot:title={'center':'education.num'}>,\n",
       "        <AxesSubplot:title={'center':'capital.gain'}>],\n",
       "       [<AxesSubplot:title={'center':'capital.loss'}>,\n",
       "        <AxesSubplot:title={'center':'hours.per.week'}>]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numeric_cols = train_df_nan.select_dtypes(\"int64\").columns.tolist()\n",
    "\n",
    "train_df_nan.hist(bins=50,figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age and fnlwgt (and maybe education.num) seem to be the most relevant features. The rest are not distributed well and are concentrated at one value._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Identify transformations to apply\n",
    "\n",
    "Next, I identify the sequence of transformations that I would apply on each column in the dataset. I am droping education because education.num carries the same data but in a preferable numeric format. I am also dropping capital.gain and capital loss due to high concentration of values around 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Transformation |\n",
    "| --- | ----------- |\n",
    "| occupation | imputation, OHE |\n",
    "| age | scaling |\n",
    "| workclass | imputation, OHE |\n",
    "| fnlwgt | scaling |\n",
    "| education | drop |\n",
    "| education.num | scaling |\n",
    "| marital.status | OHE |\n",
    "| relationship | OHE |\n",
    "| race | OHE |\n",
    "| sex | OHE |\n",
    "| capital.gain | drop |\n",
    "| capital.loss | drop |\n",
    "| hours.per.week | scaling |\n",
    "| native.country | Imputation, OHE |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature types \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"age\", \"fnlwgt\", \"education.num\", \"hours.per.week\"]\n",
    "categorical_features = [\n",
    "    \"occupation\",\n",
    "    \"workclass\",\n",
    "    \"marital.status\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"native.country\",\n",
    "]\n",
    "ordinal_features = []\n",
    "binary_features = [\"sex\"]\n",
    "drop_features = [\"education\", \"capital.gain\", \"capital.loss\"]\n",
    "passthrough_features = []\n",
    "target = \"income\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Race feature\n",
    " \n",
    "Ethically, including race feature should not be a good idea and has been in radar for many organizations to build racial equality in recent years. However, realistically speaking, since this data is from 1994 when importance of racial equality was not publicly discussed, this feature could still be of use income prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Separating feature vectors and targets  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_df_nan.drop(\"income\", axis=1)\n",
    "y_train = train_df_nan[\"income\"]\n",
    "X_test = test_df_nan.drop(\"income\", axis=1)\n",
    "y_test = test_df_nan[\"income\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note that at this stage training a Support Vectore Classifier (SVC) won't work because SVC only accepts numerical values for train data. As the name indicates, SVM is designed to find the proximity to support vectors (numeric), and the notion of distance from a string (category) is not defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Preprocessing \n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Preprocessing using `sklearn`'s `ColumnTransformer` and `Pipeline`\n",
    "\n",
    "\n",
    "let's carry out preprocessing using `sklearn`'s `ColumnTransformer` and `Pipeline`. Alternatively, we can use `make_pipeline` and `make_column_transformer` which are my recommendation because of the naming of processes.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_cols),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "            OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n",
    "        ),\n",
    "        categorical_features,\n",
    "    ),\n",
    "    (OneHotEncoder(sparse=False, drop=\"if_binary\"), binary_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artan\\miniconda3\\envs\\571\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>x0_Adm-clerical</th>\n",
       "      <th>x0_Armed-Forces</th>\n",
       "      <th>x0_Craft-repair</th>\n",
       "      <th>x0_Exec-managerial</th>\n",
       "      <th>...</th>\n",
       "      <th>x5_Scotland</th>\n",
       "      <th>x5_South</th>\n",
       "      <th>x5_Taiwan</th>\n",
       "      <th>x5_Thailand</th>\n",
       "      <th>x5_Trinadad&amp;Tobago</th>\n",
       "      <th>x5_United-States</th>\n",
       "      <th>x5_Vietnam</th>\n",
       "      <th>x5_Yugoslavia</th>\n",
       "      <th>x5_missing</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.190089</td>\n",
       "      <td>0.536275</td>\n",
       "      <td>-2.357837</td>\n",
       "      <td>-0.146378</td>\n",
       "      <td>-0.215060</td>\n",
       "      <td>-0.445951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.923301</td>\n",
       "      <td>-0.524114</td>\n",
       "      <td>0.354651</td>\n",
       "      <td>-0.146378</td>\n",
       "      <td>-0.215060</td>\n",
       "      <td>-0.445951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.996622</td>\n",
       "      <td>-0.760159</td>\n",
       "      <td>-0.420345</td>\n",
       "      <td>-0.146378</td>\n",
       "      <td>-0.215060</td>\n",
       "      <td>-0.204138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.143264</td>\n",
       "      <td>-0.552827</td>\n",
       "      <td>-0.420345</td>\n",
       "      <td>-0.146378</td>\n",
       "      <td>-0.215060</td>\n",
       "      <td>-0.042930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.849979</td>\n",
       "      <td>0.036757</td>\n",
       "      <td>-0.420345</td>\n",
       "      <td>-0.146378</td>\n",
       "      <td>-0.215060</td>\n",
       "      <td>-0.042930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19531</th>\n",
       "      <td>-0.996622</td>\n",
       "      <td>2.106533</td>\n",
       "      <td>-0.420345</td>\n",
       "      <td>-0.146378</td>\n",
       "      <td>-0.215060</td>\n",
       "      <td>-0.042930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19532</th>\n",
       "      <td>0.909729</td>\n",
       "      <td>-0.405142</td>\n",
       "      <td>0.354651</td>\n",
       "      <td>-0.146378</td>\n",
       "      <td>-0.215060</td>\n",
       "      <td>-0.042930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19533</th>\n",
       "      <td>1.203014</td>\n",
       "      <td>0.466408</td>\n",
       "      <td>-0.420345</td>\n",
       "      <td>-0.146378</td>\n",
       "      <td>4.474474</td>\n",
       "      <td>-0.042930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19534</th>\n",
       "      <td>0.176517</td>\n",
       "      <td>-0.335466</td>\n",
       "      <td>-0.032847</td>\n",
       "      <td>-0.146378</td>\n",
       "      <td>-0.215060</td>\n",
       "      <td>0.763111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19535</th>\n",
       "      <td>-1.216585</td>\n",
       "      <td>-0.253569</td>\n",
       "      <td>-0.420345</td>\n",
       "      <td>-0.146378</td>\n",
       "      <td>-0.215060</td>\n",
       "      <td>0.763111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19536 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education.num  capital.gain  capital.loss  \\\n",
       "0     -0.190089  0.536275      -2.357837     -0.146378     -0.215060   \n",
       "1     -0.923301 -0.524114       0.354651     -0.146378     -0.215060   \n",
       "2     -0.996622 -0.760159      -0.420345     -0.146378     -0.215060   \n",
       "3     -1.143264 -0.552827      -0.420345     -0.146378     -0.215060   \n",
       "4     -0.849979  0.036757      -0.420345     -0.146378     -0.215060   \n",
       "...         ...       ...            ...           ...           ...   \n",
       "19531 -0.996622  2.106533      -0.420345     -0.146378     -0.215060   \n",
       "19532  0.909729 -0.405142       0.354651     -0.146378     -0.215060   \n",
       "19533  1.203014  0.466408      -0.420345     -0.146378      4.474474   \n",
       "19534  0.176517 -0.335466      -0.032847     -0.146378     -0.215060   \n",
       "19535 -1.216585 -0.253569      -0.420345     -0.146378     -0.215060   \n",
       "\n",
       "       hours.per.week  x0_Adm-clerical  x0_Armed-Forces  x0_Craft-repair  \\\n",
       "0           -0.445951              0.0              0.0              0.0   \n",
       "1           -0.445951              0.0              0.0              0.0   \n",
       "2           -0.204138              0.0              0.0              1.0   \n",
       "3           -0.042930              0.0              0.0              1.0   \n",
       "4           -0.042930              0.0              0.0              0.0   \n",
       "...               ...              ...              ...              ...   \n",
       "19531       -0.042930              0.0              0.0              1.0   \n",
       "19532       -0.042930              0.0              0.0              0.0   \n",
       "19533       -0.042930              0.0              0.0              0.0   \n",
       "19534        0.763111              1.0              0.0              0.0   \n",
       "19535        0.763111              0.0              0.0              0.0   \n",
       "\n",
       "       x0_Exec-managerial  ...  x5_Scotland  x5_South  x5_Taiwan  x5_Thailand  \\\n",
       "0                     0.0  ...          0.0       0.0        0.0          0.0   \n",
       "1                     0.0  ...          0.0       0.0        0.0          0.0   \n",
       "2                     0.0  ...          0.0       0.0        0.0          0.0   \n",
       "3                     0.0  ...          0.0       0.0        0.0          0.0   \n",
       "4                     0.0  ...          0.0       0.0        0.0          0.0   \n",
       "...                   ...  ...          ...       ...        ...          ...   \n",
       "19531                 0.0  ...          0.0       0.0        0.0          0.0   \n",
       "19532                 0.0  ...          0.0       0.0        0.0          0.0   \n",
       "19533                 0.0  ...          0.0       0.0        0.0          0.0   \n",
       "19534                 0.0  ...          0.0       0.0        0.0          0.0   \n",
       "19535                 0.0  ...          0.0       0.0        0.0          0.0   \n",
       "\n",
       "       x5_Trinadad&Tobago  x5_United-States  x5_Vietnam  x5_Yugoslavia  \\\n",
       "0                     0.0               0.0         0.0            0.0   \n",
       "1                     0.0               1.0         0.0            0.0   \n",
       "2                     0.0               1.0         0.0            0.0   \n",
       "3                     0.0               1.0         0.0            0.0   \n",
       "4                     0.0               1.0         0.0            0.0   \n",
       "...                   ...               ...         ...            ...   \n",
       "19531                 0.0               1.0         0.0            0.0   \n",
       "19532                 0.0               1.0         0.0            0.0   \n",
       "19533                 0.0               1.0         0.0            0.0   \n",
       "19534                 0.0               1.0         0.0            0.0   \n",
       "19535                 0.0               0.0         0.0            0.0   \n",
       "\n",
       "       x5_missing  male  \n",
       "0             0.0   1.0  \n",
       "1             0.0   0.0  \n",
       "2             0.0   1.0  \n",
       "3             0.0   1.0  \n",
       "4             0.0   1.0  \n",
       "...           ...   ...  \n",
       "19531         0.0   1.0  \n",
       "19532         0.0   1.0  \n",
       "19533         0.0   1.0  \n",
       "19534         0.0   1.0  \n",
       "19535         0.0   1.0  \n",
       "\n",
       "[19536 rows x 91 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans = preprocessor.fit_transform(X_train)\n",
    "\n",
    "pd.DataFrame(\n",
    "    X_train_trans,\n",
    "    columns=numeric_cols\n",
    "    + preprocessor.named_transformers_[\"pipeline\"][\"onehotencoder\"]\n",
    "    .get_feature_names()\n",
    "    .tolist()\n",
    "    + [\"male\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the biggest advantages of pipelines in case of this example is that we can use it to construct a combination of multiple transformations which we could use to apply to one set of columns. Without this feature we wouldn't be able to call the resultant nd_array from the first transformation in order to call another transformation on.   \n",
    "Column transformers in this case are very handy because we have different column types from numeric to categorical where we want to have different tranformations for each or even drop some columns. Combination of pipeline and column transformer not only make the transformation of test data easy, but will also allow us to run cross_validate function without any leak (of test data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4: Building models \n",
    "<hr>\n",
    "\n",
    "Now that we have preprocessed features, we are ready to build models. I'm using the helper function inspired by UBC MDS lecture material. Using this function we  return mean cross-validation score along with standard deviation for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {}  # dictionary to store all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1 Baseline model \n",
    "\n",
    "1. We define a pipeline with two steps: `preprocessor` from 3.1 and `scikit-learn`'s `DummyClassifier` with default hyperparameters as our classifier.  \n",
    "2. We carry out 5-fold cross-validation with the pipeline, and store the results in `results_dict` above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.055 (+/- 0.009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.026 (+/- 0.006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.760 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.760 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         value\n",
       "fit_time     0.055 (+/- 0.009)\n",
       "score_time   0.026 (+/- 0.006)\n",
       "test_score   0.760 (+/- 0.000)\n",
       "train_score  0.760 (+/- 0.000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = make_pipeline(preprocessor, DummyClassifier())\n",
    "\n",
    "results_dict = mean_std_cross_val_scores(\n",
    "    dummy, X_train, y_train, return_train_score=True, cv=5\n",
    ")\n",
    "pd.DataFrame(results_dict, columns=[\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2 Trying different classifiers\n",
    "\n",
    "For each of the models in the `models` dictionary below we:  \n",
    "- define a pipeline with two steps: `preprocessor` from 3.1 and the model as your classifier. \n",
    "- carry out 5-fold cross-validation with the pipeline.  \n",
    "- store mean cross-validation scores, mean train scores, and `fit()` and `score()` times in `results_dict`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"decision tree\": DecisionTreeClassifier(random_state=123),\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"RBF SVM\": SVC(random_state=123),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision tree</th>\n",
       "      <th>kNN</th>\n",
       "      <th>RBF SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.227 (+/- 0.010)</td>\n",
       "      <td>0.063 (+/- 0.014)</td>\n",
       "      <td>11.572 (+/- 0.221)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.024 (+/- 0.008)</td>\n",
       "      <td>1.448 (+/- 0.091)</td>\n",
       "      <td>3.234 (+/- 0.398)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.814 (+/- 0.007)</td>\n",
       "      <td>0.831 (+/- 0.002)</td>\n",
       "      <td>0.855 (+/- 0.005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.882 (+/- 0.001)</td>\n",
       "      <td>0.867 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 decision tree                kNN             RBF SVM\n",
       "fit_time     0.227 (+/- 0.010)  0.063 (+/- 0.014)  11.572 (+/- 0.221)\n",
       "score_time   0.024 (+/- 0.008)  1.448 (+/- 0.091)   3.234 (+/- 0.398)\n",
       "test_score   0.814 (+/- 0.007)  0.831 (+/- 0.002)   0.855 (+/- 0.005)\n",
       "train_score  1.000 (+/- 0.000)  0.882 (+/- 0.001)   0.867 (+/- 0.001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = pd.DataFrame()\n",
    "for key, pair in models.items():\n",
    "    pipe = make_pipeline(preprocessor, pair)\n",
    "\n",
    "    result = mean_std_cross_val_scores(\n",
    "        pipe, X_train, y_train, return_train_score=True, cv=5\n",
    "    )\n",
    "    results_dict = pd.concat(\n",
    "        [results_dict, pd.DataFrame(result, columns=[key])], axis=1\n",
    "    )\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Discussion\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected with Decision Trees if we do not specify depth, we will get a perfect train score of 1 which is much higher than the other two. Decision tree is also the one with fastest score time. On the other side RBF SVM appears to have found a more balanced fit with lower train score but highest mean cross validation score. Fit time is the lowest for KNN as expected since the model will only be storing the values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Hyperparameter optimization\n",
    "\n",
    "In this exercise, we'll carry out hyperparameter optimization for the hyperparameter `C` of SVC RBF classifier. In practice we carry out hyperparameter optimization for all different hyperparameters for the most promising classifiers. Here we'll only do it for the `SVC` classifier for one hyperparameter: `C`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"C\": np.logspace(-2, 2, 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C = 0.01</th>\n",
       "      <th>C = 0.22</th>\n",
       "      <th>C = 4.64</th>\n",
       "      <th>C = 100.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>14.787 (+/- 0.466)</td>\n",
       "      <td>11.665 (+/- 0.159)</td>\n",
       "      <td>13.420 (+/- 0.377)</td>\n",
       "      <td>28.425 (+/- 0.841)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>4.601 (+/- 0.112)</td>\n",
       "      <td>3.455 (+/- 0.061)</td>\n",
       "      <td>3.080 (+/- 0.194)</td>\n",
       "      <td>3.319 (+/- 0.123)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.818 (+/- 0.004)</td>\n",
       "      <td>0.854 (+/- 0.006)</td>\n",
       "      <td>0.855 (+/- 0.006)</td>\n",
       "      <td>0.838 (+/- 0.004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.819 (+/- 0.003)</td>\n",
       "      <td>0.858 (+/- 0.001)</td>\n",
       "      <td>0.881 (+/- 0.002)</td>\n",
       "      <td>0.918 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       C = 0.01            C = 0.22            C = 4.64  \\\n",
       "fit_time     14.787 (+/- 0.466)  11.665 (+/- 0.159)  13.420 (+/- 0.377)   \n",
       "score_time    4.601 (+/- 0.112)   3.455 (+/- 0.061)   3.080 (+/- 0.194)   \n",
       "test_score    0.818 (+/- 0.004)   0.854 (+/- 0.006)   0.855 (+/- 0.006)   \n",
       "train_score   0.819 (+/- 0.003)   0.858 (+/- 0.001)   0.881 (+/- 0.002)   \n",
       "\n",
       "                      C = 100.0  \n",
       "fit_time     28.425 (+/- 0.841)  \n",
       "score_time    3.319 (+/- 0.123)  \n",
       "test_score    0.838 (+/- 0.004)  \n",
       "train_score   0.918 (+/- 0.001)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = pd.DataFrame()\n",
    "for c in param_grid[\"C\"]:\n",
    "    pipe = make_pipeline(preprocessor, SVC(random_state=123, C=c))\n",
    "    result = mean_std_cross_val_scores(\n",
    "        pipe, X_train, y_train, return_train_score=True, cv=5\n",
    "    )\n",
    "    results_dict = pd.concat(\n",
    "        [results_dict, pd.DataFrame(result, columns=[f\"C = {round(c,2)}\"])], axis=1\n",
    "    )\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default C value used by scikit-learn was 1 which gave the exact same score as my highest CV score of 0.855 (for C = 4.46) in this hyperparameter tuning exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Hyperparameter optimization for other models\n",
    "\n",
    "Now we go further by doing extra hyperparameter optimization. We will:\n",
    "1. Jointly optimize `C` and `gamma` hyperparameters of SVC. \n",
    "2. Carry out hyperparameter optimization for other classifiers.  \n",
    "3. Comment on your results. Are you getting a better model? \n",
    "\n",
    "> Note: In later notebooks I will use proper hyperparameter optimization using `sklearn`'s **`RandomizedSearchCV`** and **`GridSearchCV`** instead a nested for loop. Running the below code you will see that for loops are not very optimized when it comes to calculating cross validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append(mean_scores[i])\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [0.01, 0.1, 1]\n",
    "C = [0.01, 1, 100]\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for gamma in gammas:\n",
    "    for c in C:\n",
    "        pipe = make_pipeline(preprocessor, SVC(random_state=123, C=c, gamma=gamma))\n",
    "        result = mean_cross_val_scores(pipe, X_train, y_train, cv=5)\n",
    "        result_df = pd.DataFrame(\n",
    "            [c, gamma, result[2]], index=[\"C\", \"gamma\", \"CV_score\"]\n",
    "        )\n",
    "\n",
    "        results = pd.concat([results, result_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gamma</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.10</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.764947</td>\n",
       "      <td>0.815827</td>\n",
       "      <td>0.759674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.853758</td>\n",
       "      <td>0.855191</td>\n",
       "      <td>0.817414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>0.854423</td>\n",
       "      <td>0.834767</td>\n",
       "      <td>0.794124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gamma       0.01      0.10      1.00\n",
       "C                                   \n",
       "0.01    0.764947  0.815827  0.759674\n",
       "1.00    0.853758  0.855191  0.817414\n",
       "100.00  0.854423  0.834767  0.794124"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.T.pivot(index=\"C\", columns=\"gamma\", values=\"CV_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the scores above it seems like a gamma value of 0.1 and C value of 1 gives the best performance. This score is very identical to the validation score from default SVC hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 5: Evaluating on the test set\n",
    "<hr>\n",
    "\n",
    "Now that we have a best performing model, it's time to assess our model on the set aside test set. We'll examine whether the results we obtained using cross-validation on the train set are consistent with the results on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Scoring on the unseen test set \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test score for our optimized model is 0.856\n"
     ]
    }
   ],
   "source": [
    "final_pipe = make_pipeline(preprocessor, SVC(random_state=123, C=1, gamma=0.1))\n",
    "\n",
    "final_pipe.fit(X_train, y_train)\n",
    "final_score = final_pipe.score(X_test, y_test)\n",
    "print(\"The test score for our optimized model is {0:.3f}\".format(final_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cross_validation score and test score are very consistent showing that the model is generalizing well.\n",
    "- Considering the high number of training data and similar scores for CV and test data, I am confident that this model will perform similar on deployment data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:571]",
   "language": "python",
   "name": "conda-env-571-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
