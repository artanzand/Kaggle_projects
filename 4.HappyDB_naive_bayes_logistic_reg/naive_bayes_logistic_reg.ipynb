{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes and Logistic Regression\n",
    "\n",
    "Naive Bayes is popular in text classification tasks and sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import altair as alt\n",
    "alt.renderers.enable(\"mimetype\")\n",
    "alt.data_transformers.enable('data_server')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Classifying happy moments \n",
    "<hr>\n",
    "\n",
    "We will use [HappyDB](https://www.kaggle.com/ritresearch/happydb) corpus which contains about 100,000 happy moments classified into 7 categories: *affection, exercise, bonding, nature, leisure, achievement, enjoy_the_moment*. The data was crowd-sourced via [Amazon Mechanical Turk](https://www.mturk.com/). The ground truth label is not available for all examples, and in this project, we'll only use the examples where ground truth is available (~15,000 examples). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>ground_truth_category</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27676</th>\n",
       "      <td>206</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27678</th>\n",
       "      <td>45</td>\n",
       "      <td>24h</td>\n",
       "      <td>I meditated last night.</td>\n",
       "      <td>I meditated last night.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>leisure</td>\n",
       "      <td>leisure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27697</th>\n",
       "      <td>498</td>\n",
       "      <td>24h</td>\n",
       "      <td>My grandmother start to walk from the bed afte...</td>\n",
       "      <td>My grandmother start to walk from the bed afte...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27705</th>\n",
       "      <td>5732</td>\n",
       "      <td>24h</td>\n",
       "      <td>I picked my daughter up from the airport and w...</td>\n",
       "      <td>I picked my daughter up from the airport and w...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>bonding</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27715</th>\n",
       "      <td>2272</td>\n",
       "      <td>24h</td>\n",
       "      <td>when i received flowers from my best friend</td>\n",
       "      <td>when i received flowers from my best friend</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wid reflection_period  \\\n",
       "hmid                            \n",
       "27676   206               24h   \n",
       "27678    45               24h   \n",
       "27697   498               24h   \n",
       "27705  5732               24h   \n",
       "27715  2272               24h   \n",
       "\n",
       "                                             original_hm  \\\n",
       "hmid                                                       \n",
       "27676  We had a serious talk with some friends of our...   \n",
       "27678                            I meditated last night.   \n",
       "27697  My grandmother start to walk from the bed afte...   \n",
       "27705  I picked my daughter up from the airport and w...   \n",
       "27715        when i received flowers from my best friend   \n",
       "\n",
       "                                              cleaned_hm  modified  \\\n",
       "hmid                                                                 \n",
       "27676  We had a serious talk with some friends of our...      True   \n",
       "27678                            I meditated last night.      True   \n",
       "27697  My grandmother start to walk from the bed afte...      True   \n",
       "27705  I picked my daughter up from the airport and w...      True   \n",
       "27715        when i received flowers from my best friend      True   \n",
       "\n",
       "       num_sentence ground_truth_category predicted_category  \n",
       "hmid                                                          \n",
       "27676             2               bonding            bonding  \n",
       "27678             1               leisure            leisure  \n",
       "27697             1             affection          affection  \n",
       "27705             1               bonding          affection  \n",
       "27715             1               bonding            bonding  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../downloads/cleaned_hm.csv\", index_col=0)\n",
    "sample_df = df.dropna()\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yXKa7qfQXYPD",
    "outputId": "8bbf5eeb-0151-4853-a49c-3876279bbeb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>moment</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27676</th>\n",
       "      <td>206</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27678</th>\n",
       "      <td>45</td>\n",
       "      <td>24h</td>\n",
       "      <td>I meditated last night.</td>\n",
       "      <td>I meditated last night.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>leisure</td>\n",
       "      <td>leisure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27697</th>\n",
       "      <td>498</td>\n",
       "      <td>24h</td>\n",
       "      <td>My grandmother start to walk from the bed afte...</td>\n",
       "      <td>My grandmother start to walk from the bed afte...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27705</th>\n",
       "      <td>5732</td>\n",
       "      <td>24h</td>\n",
       "      <td>I picked my daughter up from the airport and w...</td>\n",
       "      <td>I picked my daughter up from the airport and w...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>bonding</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27715</th>\n",
       "      <td>2272</td>\n",
       "      <td>24h</td>\n",
       "      <td>when i received flowers from my best friend</td>\n",
       "      <td>when i received flowers from my best friend</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128726</th>\n",
       "      <td>566</td>\n",
       "      <td>24h</td>\n",
       "      <td>yesterday chat with my brother in video call i...</td>\n",
       "      <td>yesterday chat with my brother in video call i...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128736</th>\n",
       "      <td>1580</td>\n",
       "      <td>24h</td>\n",
       "      <td>learning how to better hunt for hits on amazon...</td>\n",
       "      <td>learning how to better hunt for hits on amazon...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>achievement</td>\n",
       "      <td>achievement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128746</th>\n",
       "      <td>248</td>\n",
       "      <td>24h</td>\n",
       "      <td>I woke up in the middle of the night and reali...</td>\n",
       "      <td>I woke up in the middle of the night and reali...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>enjoy_the_moment</td>\n",
       "      <td>enjoy_the_moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128758</th>\n",
       "      <td>4428</td>\n",
       "      <td>24h</td>\n",
       "      <td>Yesterday my relations came to my house. That ...</td>\n",
       "      <td>Yesterday my relations came to my house. That ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>affection</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128764</th>\n",
       "      <td>3934</td>\n",
       "      <td>24h</td>\n",
       "      <td>Cuddling with my girlfriend last night.</td>\n",
       "      <td>Cuddling with my girlfriend last night.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>affection</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14125 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         wid reflection_period  \\\n",
       "hmid                             \n",
       "27676    206               24h   \n",
       "27678     45               24h   \n",
       "27697    498               24h   \n",
       "27705   5732               24h   \n",
       "27715   2272               24h   \n",
       "...      ...               ...   \n",
       "128726   566               24h   \n",
       "128736  1580               24h   \n",
       "128746   248               24h   \n",
       "128758  4428               24h   \n",
       "128764  3934               24h   \n",
       "\n",
       "                                              original_hm  \\\n",
       "hmid                                                        \n",
       "27676   We had a serious talk with some friends of our...   \n",
       "27678                             I meditated last night.   \n",
       "27697   My grandmother start to walk from the bed afte...   \n",
       "27705   I picked my daughter up from the airport and w...   \n",
       "27715         when i received flowers from my best friend   \n",
       "...                                                   ...   \n",
       "128726  yesterday chat with my brother in video call i...   \n",
       "128736  learning how to better hunt for hits on amazon...   \n",
       "128746  I woke up in the middle of the night and reali...   \n",
       "128758  Yesterday my relations came to my house. That ...   \n",
       "128764            Cuddling with my girlfriend last night.   \n",
       "\n",
       "                                                   moment  modified  \\\n",
       "hmid                                                                  \n",
       "27676   We had a serious talk with some friends of our...      True   \n",
       "27678                             I meditated last night.      True   \n",
       "27697   My grandmother start to walk from the bed afte...      True   \n",
       "27705   I picked my daughter up from the airport and w...      True   \n",
       "27715         when i received flowers from my best friend      True   \n",
       "...                                                   ...       ...   \n",
       "128726  yesterday chat with my brother in video call i...     False   \n",
       "128736  learning how to better hunt for hits on amazon...      True   \n",
       "128746  I woke up in the middle of the night and reali...      True   \n",
       "128758  Yesterday my relations came to my house. That ...      True   \n",
       "128764            Cuddling with my girlfriend last night.      True   \n",
       "\n",
       "        num_sentence            target predicted_category  \n",
       "hmid                                                       \n",
       "27676              2           bonding            bonding  \n",
       "27678              1           leisure            leisure  \n",
       "27697              1         affection          affection  \n",
       "27705              1           bonding          affection  \n",
       "27715              1           bonding            bonding  \n",
       "...              ...               ...                ...  \n",
       "128726             1         affection          affection  \n",
       "128736             1       achievement        achievement  \n",
       "128746             1  enjoy_the_moment   enjoy_the_moment  \n",
       "128758             2         affection          affection  \n",
       "128764             1         affection          affection  \n",
       "\n",
       "[14125 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = sample_df.rename(\n",
    "    columns={\"cleaned_hm\": \"moment\", \"ground_truth_category\": \"target\"}\n",
    ")\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(sample_df, test_size=0.3, random_state=123)\n",
    "X_train, y_train = train_df[\"moment\"], train_df[\"target\"]\n",
    "X_test, y_test = test_df[\"moment\"], test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "### 1.1 Distribution of target values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v4+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v4.8.1.json",
       "config": {
        "view": {
         "continuousHeight": 300,
         "continuousWidth": 400
        }
       },
       "data": {
        "url": "http://localhost:22171/23f9b2086d674a24cae637fbdfbbf34f.json"
       },
       "encoding": {
        "x": {
         "aggregate": "count",
         "type": "quantitative"
        },
        "y": {
         "field": "target",
         "type": "nominal"
        }
       },
       "mark": "bar"
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 4 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(pd.DataFrame(y_train)).mark_bar().encode(y=\"target\", x=\"count()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achievement and Affection seem to be the target the most often and Exercise and Nature the least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 DummyClassifier \n",
    "\n",
    "We report mean cross-validation scores for `DummyClassifier`. The low mean cross-validation score can be attributed to the distribution of targets. Since `DummyClassifier` uses the most frequent target (affection in this case) as prediction, if we find its frequency we will have our CV score.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from MDS notes\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.007 (+/- 0.003)\n",
       "score_time     0.002 (+/- 0.002)\n",
       "test_score     0.343 (+/- 0.000)\n",
       "train_score    0.343 (+/- 0.000)\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_cross_val_scores(DummyClassifier(), X_train, y_train, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34257105289774453"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We get the same score calculated by DummyClassifier this way\n",
    "y_train.value_counts()[\"affection\"] / y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3 Different classifiers \n",
    "\n",
    "For each model in the starter code below, we carry out 5-fold cross-validation and report mean cross-validation scores, mean train scores, and mean fit and score times. \n",
    "\n",
    "> Note that in the given text, we use CountVectorizer with `binary=False` argument to extract binary features. The binary features (0/1) could be passed to `BernoulliNB`.\n",
    "> `alpha` is by default set to 1 to apply smoothing on the final prediction of the model (to overcome the division over zero problem).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"RBF SVM\": SVC(),\n",
    "    \"BernoulliNB\": BernoulliNB(alpha=1),\n",
    "    \"MultinomialNB\": MultinomialNB(alpha=1),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, multi_class=\"ovr\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>BernoulliNB</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.697 (+/- 0.026)</td>\n",
       "      <td>6.440 (+/- 0.038)</td>\n",
       "      <td>0.147 (+/- 0.009)</td>\n",
       "      <td>0.141 (+/- 0.011)</td>\n",
       "      <td>0.938 (+/- 0.045)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.037 (+/- 0.009)</td>\n",
       "      <td>0.960 (+/- 0.009)</td>\n",
       "      <td>0.031 (+/- 0.000)</td>\n",
       "      <td>0.034 (+/- 0.007)</td>\n",
       "      <td>0.047 (+/- 0.016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.763 (+/- 0.010)</td>\n",
       "      <td>0.801 (+/- 0.013)</td>\n",
       "      <td>0.681 (+/- 0.004)</td>\n",
       "      <td>0.759 (+/- 0.007)</td>\n",
       "      <td>0.824 (+/- 0.005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.997 (+/- 0.000)</td>\n",
       "      <td>0.930 (+/- 0.001)</td>\n",
       "      <td>0.761 (+/- 0.002)</td>\n",
       "      <td>0.861 (+/- 0.002)</td>\n",
       "      <td>0.940 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Decision Tree            RBF SVM        BernoulliNB  \\\n",
       "fit_time     0.697 (+/- 0.026)  6.440 (+/- 0.038)  0.147 (+/- 0.009)   \n",
       "score_time   0.037 (+/- 0.009)  0.960 (+/- 0.009)  0.031 (+/- 0.000)   \n",
       "test_score   0.763 (+/- 0.010)  0.801 (+/- 0.013)  0.681 (+/- 0.004)   \n",
       "train_score  0.997 (+/- 0.000)  0.930 (+/- 0.001)  0.761 (+/- 0.002)   \n",
       "\n",
       "                 MultinomialNB Logistic Regression  \n",
       "fit_time     0.141 (+/- 0.011)   0.938 (+/- 0.045)  \n",
       "score_time   0.034 (+/- 0.007)   0.047 (+/- 0.016)  \n",
       "test_score   0.759 (+/- 0.007)   0.824 (+/- 0.005)  \n",
       "train_score  0.861 (+/- 0.002)   0.940 (+/- 0.001)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "for key, value in models.items():\n",
    "    if key == \"BernoulliNB\":\n",
    "        pipe = make_pipeline(CountVectorizer(stop_words='english', binary=True), value)\n",
    "    else:\n",
    "        pipe = make_pipeline(CountVectorizer(stop_words='english',), value)\n",
    "    results[key] = mean_std_cross_val_scores(\n",
    "        pipe, X_train, y_train, return_train_score=True\n",
    "    )\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic regression has the highest CV score and the gap between CV and train score are small, showing that the model is performing well. After that are RBF SVM followed closely by Multinomial Naive Bayes both having lower CV scores, but small gaps between CV and train score. Among these Multinomial and Bernoulli Naive Bayes have the fastest fit time and score time. The very high trains score and low cross validation score for the decision tree implies overfitting.\n",
    "2. Our target in this case has multiple classes. This is how each model in the list above might be tackling multi-class classification.\n",
    ">Decision Tree: Same as binary classification, the end of each leaf could be a different class.  \n",
    ">RBF SVM: Through the \"one-vs-one\" approach for multi-class classification a total of n * (n - 1) / 2 classifiers are constructed and each one trains data from two classes.   \n",
    ">Naive Bayes: We can use the similar concept used for binary classification, but this time condition on multiple classes.  \n",
    ">Logistic Regression: Multi-class classification is done using \"one-vs-rest\" or \"one-vs-one\" methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Hyperparameter optimization \n",
    "We will:\n",
    "1. Define a pipeline with `CountVectorizer` and `LogisitcRegression` with `max_iter=2000` and `multi_class='ovr'`.\n",
    "2. Using `RandomizedSearchCV`, jointly optimize `C` and `max_features` of logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                              CountVectorizer(stop_words='english')),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(max_iter=2000,\n",
       "                                                                 multi_class='ovr'))]),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'countvectorizer__max_features': array([5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000,\n",
       "       6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100,\n",
       "       7200, 7300, 7400, 7500, 7600, 7700, 7800, 7900, 8000, 8100, 8200,\n",
       "       8300, 8400, 8500, 8600, 8700, 8800, 8900, 9000, 9100, 9200, 9300,\n",
       "       9400, 9500, 9600, 9700, 9800, 9900]),\n",
       "                                        'logisticregression__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000281BACF58E0>},\n",
       "                   random_state=2021, return_train_score=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import uniform, loguniform\n",
    "\n",
    "hyper_pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words=\"english\"),\n",
    "    LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        multi_class=\"ovr\",  # one-vs-rest\n",
    "    ),\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    \"countvectorizer__max_features\": np.arange(5000, 10000, 100),\n",
    "    \"logisticregression__C\": loguniform(1e-1, 1e2),\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    hyper_pipe,\n",
    "    param_distributions,\n",
    "    n_iter=20,\n",
    "    random_state=2021,\n",
    "    return_train_score=True,\n",
    ")\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826538918492901"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__max_features': 7900,\n",
       " 'logisticregression__C': 2.2721433695433677}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7900</td>\n",
       "      <td>2.272143</td>\n",
       "      <td>0.826539</td>\n",
       "      <td>0.966749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9200</td>\n",
       "      <td>3.824791</td>\n",
       "      <td>0.825325</td>\n",
       "      <td>0.976434</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7500</td>\n",
       "      <td>1.005352</td>\n",
       "      <td>0.823909</td>\n",
       "      <td>0.940629</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6900</td>\n",
       "      <td>0.85794</td>\n",
       "      <td>0.822696</td>\n",
       "      <td>0.932968</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9800</td>\n",
       "      <td>0.71106</td>\n",
       "      <td>0.821178</td>\n",
       "      <td>0.925331</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7600</td>\n",
       "      <td>8.520291</td>\n",
       "      <td>0.820976</td>\n",
       "      <td>0.984601</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9900</td>\n",
       "      <td>9.589561</td>\n",
       "      <td>0.820470</td>\n",
       "      <td>0.985309</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8300</td>\n",
       "      <td>10.737467</td>\n",
       "      <td>0.819863</td>\n",
       "      <td>0.985966</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9500</td>\n",
       "      <td>11.599434</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.986346</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8600</td>\n",
       "      <td>15.728057</td>\n",
       "      <td>0.817840</td>\n",
       "      <td>0.988192</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7100</td>\n",
       "      <td>15.852877</td>\n",
       "      <td>0.817638</td>\n",
       "      <td>0.988015</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7900</td>\n",
       "      <td>18.145807</td>\n",
       "      <td>0.817335</td>\n",
       "      <td>0.988773</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5600</td>\n",
       "      <td>22.53878</td>\n",
       "      <td>0.814098</td>\n",
       "      <td>0.987484</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6400</td>\n",
       "      <td>0.384847</td>\n",
       "      <td>0.813289</td>\n",
       "      <td>0.894710</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7700</td>\n",
       "      <td>33.997569</td>\n",
       "      <td>0.812985</td>\n",
       "      <td>0.991757</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9900</td>\n",
       "      <td>77.898495</td>\n",
       "      <td>0.806917</td>\n",
       "      <td>0.994184</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9400</td>\n",
       "      <td>98.113743</td>\n",
       "      <td>0.805299</td>\n",
       "      <td>0.994412</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5600</td>\n",
       "      <td>48.577787</td>\n",
       "      <td>0.805197</td>\n",
       "      <td>0.990922</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5100</td>\n",
       "      <td>77.12372</td>\n",
       "      <td>0.800141</td>\n",
       "      <td>0.991934</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8700</td>\n",
       "      <td>0.181924</td>\n",
       "      <td>0.799028</td>\n",
       "      <td>0.858147</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_countvectorizer__max_features param_logisticregression__C  \\\n",
       "11                                7900                    2.272143   \n",
       "19                                9200                    3.824791   \n",
       "15                                7500                    1.005352   \n",
       "17                                6900                     0.85794   \n",
       "9                                 9800                     0.71106   \n",
       "18                                7600                    8.520291   \n",
       "12                                9900                    9.589561   \n",
       "6                                 8300                   10.737467   \n",
       "1                                 9500                   11.599434   \n",
       "16                                8600                   15.728057   \n",
       "0                                 7100                   15.852877   \n",
       "4                                 7900                   18.145807   \n",
       "5                                 5600                    22.53878   \n",
       "13                                6400                    0.384847   \n",
       "3                                 7700                   33.997569   \n",
       "10                                9900                   77.898495   \n",
       "2                                 9400                   98.113743   \n",
       "14                                5600                   48.577787   \n",
       "7                                 5100                    77.12372   \n",
       "8                                 8700                    0.181924   \n",
       "\n",
       "    mean_test_score  mean_train_score  rank_test_score  \n",
       "11         0.826539          0.966749                1  \n",
       "19         0.825325          0.976434                2  \n",
       "15         0.823909          0.940629                3  \n",
       "17         0.822696          0.932968                4  \n",
       "9          0.821178          0.925331                5  \n",
       "18         0.820976          0.984601                6  \n",
       "12         0.820470          0.985309                7  \n",
       "6          0.819863          0.985966                8  \n",
       "1          0.819155          0.986346                9  \n",
       "16         0.817840          0.988192               10  \n",
       "0          0.817638          0.988015               11  \n",
       "4          0.817335          0.988773               12  \n",
       "5          0.814098          0.987484               13  \n",
       "13         0.813289          0.894710               14  \n",
       "3          0.812985          0.991757               15  \n",
       "10         0.806917          0.994184               16  \n",
       "2          0.805299          0.994412               17  \n",
       "14         0.805197          0.990922               18  \n",
       "7          0.800141          0.991934               19  \n",
       "8          0.799028          0.858147               20  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_)[\n",
    "    [\"param_countvectorizer__max_features\",\n",
    "     \"param_logisticregression__C\",\n",
    "     \"mean_test_score\",\n",
    "     \"mean_train_score\",\n",
    "     \"rank_test_score\"]\n",
    "].sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting similar average cross validation score compared to the default values.\n",
    "The best model has slightly higher score compared to the next couple of scores.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Model interpretation \n",
    "<hr>\n",
    "\n",
    "One of the primary advantage of linear models is their ability to interpret models in terms of important features by exploring the weights learned by the logistic regression classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Most informative words\n",
    "\n",
    "We will use the best estimator from 3.7 to get\n",
    "    - first 5 words that are positively associated and first 5 words which are negatively associated with the class \"affection\". \n",
    "    - first 5 words that are positively associated and first 5 words which are negatively associated with the class \"exercise\". \n",
    "\n",
    "\n",
    "> This information is exposed by the `coef_` attribute of [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) object. For multiclass classification, for each class the models learns coefficients per feature for that class. \n",
    "\n",
    "> The vocabulary (mapping from feature indices to actual words) is obtained by calling `get_feature_names_out()` on the `CountVectorizer` object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positively associated with 'affection':\n",
      "    husband, wife, brother, son, daughter\n",
      "Negatively associated with 'affection':\n",
      "    friend, unforgettable, exam, friends, police\n",
      "Positively associated with 'exercise':\n",
      "    gym, workout, exercise, yoga, exercised\n",
      "Negatively associated with 'exercise':\n",
      "    dog, daughter, just, got, movie\n"
     ]
    }
   ],
   "source": [
    "vocabs = random_search.best_estimator_[\"countvectorizer\"].get_feature_names_out()\n",
    "coeffs = random_search.best_estimator_[\"logisticregression\"].coef_\n",
    "targets = random_search.classes_\n",
    "random_search_df = pd.DataFrame(coeffs, columns=vocabs).set_index(targets).T\n",
    "\n",
    "pos_affection = (\n",
    "    random_search_df.sort_values(\"affection\", ascending=False).head().index.tolist()\n",
    ")\n",
    "neg_affection = random_search_df.sort_values(\"affection\").head().index.tolist()\n",
    "\n",
    "pos_exercise = (\n",
    "    random_search_df.sort_values(\"exercise\", ascending=False).head().index.tolist()\n",
    ")\n",
    "neg_exercise = random_search_df.sort_values(\"exercise\").head().index.tolist()\n",
    "\n",
    "print(\"Positively associated with 'affection':\")\n",
    "print(\"   \", \", \".join(pos_affection))\n",
    "print(\"Negatively associated with 'affection':\")\n",
    "print(\"   \", \", \".join(neg_affection))\n",
    "\n",
    "print(\"Positively associated with 'exercise':\")\n",
    "print(\"   \", \", \".join(pos_exercise))\n",
    "print(\"Negatively associated with 'exercise':\")\n",
    "print(\"   \", \", \".join(neg_exercise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The positively associated words for affection and exercise make sense. However, it is hard to justify the negative words. It is very helpful to see what features our model is using to predict. For example, we have both `friend` and `friends` in our negatively associated affection list. Knowing this we would be able to do some further data transformation to minimize this nuisance and improve performance. The other thing that we could do by looking at these features is whether the features with highest weights really make sense.  \n",
    "- It would be very hard to get the most informative features in other classifier. We could say that the top most point of a decision tree (root) is the most important feature, but that is not very informative in most of the cases. For SVM the most important features are multiple observations (arrays) which do not give any intuitive information. For Naive Bayes models, it would be very hard to find the features that contribute the most to the model especially if we have a multiclass target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Test score and final evaluation\n",
    "<hr>\n",
    "\n",
    "Let's examine the performance of our best model on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Evaluation on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_maxfeature = list(random_search.best_params_.values())[0]\n",
    "best_C = list(random_search.best_params_.values())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8187824445493157"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_pipe = make_pipeline(\n",
    "    CountVectorizer(\n",
    "        stop_words=\"english\", \n",
    "        max_features=best_maxfeature\n",
    "    ),\n",
    "    LogisticRegression(\n",
    "        C=best_C,\n",
    "        max_iter=2000,\n",
    "        multi_class=\"ovr\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "optimized_pipe.fit(X_train, y_train)\n",
    "optimized_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test score is very close to the cross validation score. Considering the large amount of data that has been used to train the model, we are confident that this model will be able to perform well for the population that the information was collected from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Evaluation using probability scores\n",
    "\n",
    "Using this model, we will try to find the moments in the test set: \n",
    "\n",
    "1. where the model is most confident that the moment belongs to class \"achievement\" (i.e., an example with highest predicted probability for class \"achievement\")\n",
    "2. where the model is most confident that the moment belongs to class \"nature\" (i.e., an example with the highest predicted probability of being \"nature\")\n",
    "\n",
    "In each case, print out the moment and the associated probability score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most confident for class 'achievement':\n",
      "Prob score: 0.9998551907675534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'An event that made me happy in the past 24 hours was when I was able to get a medical bill written off completely. The hospital had not followed proper procedures to get insurance approval for the treatment, which was a violation of their contract with the insurance company. Because of this the insurance company denied the claim and stated that I did not have to pay the bill. After spending 2.5 hours on the phone with the hospital and insurance company today it was concluded that the insurance company was correct and I did not have to pay the money.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_df = pd.DataFrame(random_search.predict_proba(X_test), columns=targets)\n",
    "\n",
    "max_achiev = prob_df[\"achievement\"].idxmax()\n",
    "max_achiev_prob = prob_df[\"achievement\"].max()\n",
    "\n",
    "print(\"Most confident for class 'achievement':\")\n",
    "print(\"Prob score:\", max_achiev_prob)\n",
    "X_test.iloc[max_achiev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most confident for class 'nature':\n",
      "Prob score: 0.9475748027062482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lucky to live in the country in New York on acres of land. A highlight of my trip was taking Ferg out for a hike in the woods with my cousin. I watched him sniff every possible thing in sight, while continuing to check in and make sure we were still with him.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_nature = prob_df[\"nature\"].idxmax()\n",
    "max_nature_prob = prob_df[\"nature\"].max()\n",
    "print(\"Most confident for class 'nature':\")\n",
    "print(\"Prob score:\", max_nature_prob)\n",
    "X_test.iloc[max_nature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27b53d359d7a9441",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.3 Fake moments \n",
    "\n",
    "We can test the best model on some fake moments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_moments = [\n",
    "    \"On the weekend, I spent some quality time with my best friend.\",\n",
    "    \"I love my kids!\",\n",
    "    \"I went for a hike in the forest.\",\n",
    "    \"I did yoga this morning.\",\n",
    "    \"I am still breathing and I am alive!\",\n",
    "    \"I am going to sleep\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bonding', 'affection', 'leisure', 'exercise', 'achievement',\n",
       "       'leisure'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_pipe.predict(test_moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions look very promising, and except for one, are very accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Summary and wrap up\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1: Qualitative comparison of classifiers \n",
    "\n",
    "So far I have been trying multiple models in this Kaggle repo and thought I will create a table with strengths and weaknesses:\n",
    "\n",
    "<br>\n",
    "\n",
    "Classifier |      Strengths | Weaknesses | Key hyperparameters |\n",
    ":-----------|      :------------|:------------|:---------------------|\n",
    "decision tree | Interpretable; Fast; $\\mathcal{O}(\\log n)$ prediction cost | Unstable with respect to data; prone to overfitting: sensitive to `max_depth` hyperparameter. | `max_depth` |\n",
    "$k$-NN | Minimal training; few moving parts. Runs somewhere between $\\mathcal{O}(d \\log n)$ and $\\mathcal{O}(dn)$, can learn complex decision boundaries | Sensitive to feature scaling, choice of $k$; curse of dimensionality; doesn't work well with sparse data | `k` (`n_neighbors` in `sklearn`) |\n",
    "SVM | Powerful; prediction cost $\\propto$ number of support vectors; works well with sparse data; able to learn complex functions  | Slow; doesn't scale well, sensitive to feature scaling and careful tuning of the hyperparameters `C` and `gamma`; Training is $\\mathcal{O}(dn^2)$ | `C`, `gamma` |\n",
    "naive Bayes | Fast; scales well; works well with sparse data; natural probabilistic interpretation. | Conditional independence often unrealistic; generalization performance is usually not that great | `alpha` |\n",
    "logistic regression | Outputs have a nice probabilistic interpretation; Scales well; training time complexity is $\\mathcal{O}(dn)$; works well with sparse data; the learned coefficient provide a nice interpretation for feature importances | doesn't work well when the decision boundaries are non-linear | `C` |"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:571]",
   "language": "python",
   "name": "conda-env-571-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
