{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Feature engineering, feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, RidgeCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    ShuffleSplit,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    PolynomialFeatures,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Feature engineering \n",
    "<hr>\n",
    "\n",
    "One of the most important aspects which influences performance of machine learning models is the features used to represent the problem. If your underlying representation is bad whatever fancy model you use is not going to help. With a better feature representation, a simple and a more interpretable model is likely to perform reasonably well. \n",
    "\n",
    "\n",
    "\n",
    "**Feature engineering** is the process of transforming raw data into features that better represent the underlying problem to the predictive models. \n",
    "\n",
    "### 1.1 The data\n",
    "\n",
    "In this exercise we'll engineer our own features on [the Disaster Tweets dataset](https://www.kaggle.com/vstepanenko/disaster-tweets). We are trying to predict whether the content of a tweet is a real disaster or not. \n",
    "\n",
    "Note that coming up with features is difficult, time-consuming, and requires expert knowledge. Since we'll be using simplistic features, we might not get better scores with our engineered features. The purpose here is to make familiar with the process of feature engineering rather than getting the best scores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>debris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unfortunately, both plans fail as the 3 are im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>crash</td>\n",
       "      <td>SLC</td>\n",
       "      <td>I hope this causes Bernie to crash and bern. S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>collide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>—pushes himself up from the chair beneath to r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Widow of CIA agent killed in 2009 Afghanistan ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>screaming</td>\n",
       "      <td>Azania</td>\n",
       "      <td>As soon as God say yes they'll be screaming we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword location  \\\n",
       "3289          debris      NaN   \n",
       "2672           crash      SLC   \n",
       "2436         collide      NaN   \n",
       "9622  suicide%20bomb      NaN   \n",
       "8999       screaming   Azania   \n",
       "\n",
       "                                                   text  target  \n",
       "3289  Unfortunately, both plans fail as the 3 are im...       0  \n",
       "2672  I hope this causes Bernie to crash and bern. S...       0  \n",
       "2436  —pushes himself up from the chair beneath to r...       0  \n",
       "9622  Widow of CIA agent killed in 2009 Afghanistan ...       1  \n",
       "8999  As soon as God say yes they'll be screaming we...       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../downloads/tweets.csv\", usecols=[\"keyword\", \"text\", \"target\", \"location\"])\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=2)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(columns=[\"target\"]), train_df[\"target\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"target\"]), test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- According to the below calculations we see that there is a class imbalance. We definitely need to deal with the class imbalance because the difference between 81% and 18% seems large.\n",
    "- Assuming that we use this for a real situations (and we want to send out forces to help victims before it is too late), it is very important to have a high precision meaning that we want to know the number of tweets that we correctly labeled \"disaster\" from the list of tweets that are reporting a disaster in reality. I will also be using f1 score to make sure I don't get really low recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.812995\n",
       "1    0.187005\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Setting scoring metrics to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metrics = [\"precision\", \"f1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The location feature\n",
    "\n",
    "The location feature seems quite messy. I see two challenges that would be involved in encoding the location feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first challenge would be the high ratio of NA's and the second is that this looks like a free text without any structure. For example in some examples name of a city has been used where in other observations it is a country or state. Also, there is a use of emoticons which should be translated to text.\n",
    "2. More than a third of the values are unique. In order to reduce the number of unique values, I will use some wrangling and built-in string match functionality of pandas to see if I can replace the name of the cities and states with countries (using list of cities and countries from another dataframe). I will also use a library like spacymoji to translate emoji's to text in order to see if I can get name of any flags translated to country names. After extracting as much country as I could, I will use OneHotEncoder and only provide the categories of the 192 countries. Instead of the last step, I could alternatively use CountVectorizer and use an `n-gram range` of 1 to 3 (because name of some countries is comprised of multiple names) and use `min_df` to ignore the locations that have lower frequency that the threshold that I specify in order to remove the ones that only appear for one or two times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3746"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['location'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'SLC', 'Azania', 'United States',\n",
       "       'Amphoe Mueang Nakhon Ratchasim', 'Accra, Ghana', 'Lagos, Nigeria',\n",
       "       'Rohnert Park, CA', 'Brighton', 'Hell,Hades,Mictlan,Tartarus'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['location'].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States                     80\n",
       "Australia                         68\n",
       "London, England                   66\n",
       "UK                                62\n",
       "India                             60\n",
       "                                  ..\n",
       "Arizona City, AZ                   1\n",
       "Yorkshire & Scotland               1\n",
       "th: hakuna matata                  1\n",
       "Tacloban City, Eastern Visayas     1\n",
       "Greater Manchester                 1\n",
       "Name: location, Length: 3746, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0% of the values in the location column are missing.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{round(100 * sum(X_train['location'].isna()) / X_train.shape[0], 1)}% of the values in the location column are missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Identifying feature types\n",
    "\n",
    "In preparation for building a classifier, we identify different feature types and set up a column transformer that performs the feature transformations you deem sensible.\n",
    "\n",
    "> Note: for `CountVectorizer` transformer, we need to pass a 1-D array or a pandas.Series. So in a column transformer, we pass a string rather than a list of features for this transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I am dropping the location column as it does not provide any useful information and is in a free text format.\n",
    "- I will be watching that my number of features won't grow more than my observations (m < n). I will use a Countvectorizer for the `text` column and will use max_feature to limit the number of columns. If not specified, it will give me more than 23,000 feature columns.\n",
    "- For the `keyword` column I will use a OneHotEncoder as it is a categorical column with 200 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>debris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unfortunately, both plans fail as the 3 are im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>crash</td>\n",
       "      <td>SLC</td>\n",
       "      <td>I hope this causes Bernie to crash and bern. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>collide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>—pushes himself up from the chair beneath to r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Widow of CIA agent killed in 2009 Afghanistan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>screaming</td>\n",
       "      <td>Azania</td>\n",
       "      <td>As soon as God say yes they'll be screaming we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword location  \\\n",
       "3289          debris      NaN   \n",
       "2672           crash      SLC   \n",
       "2436         collide      NaN   \n",
       "9622  suicide%20bomb      NaN   \n",
       "8999       screaming   Azania   \n",
       "\n",
       "                                                   text  \n",
       "3289  Unfortunately, both plans fail as the 3 are im...  \n",
       "2672  I hope this causes Bernie to crash and bern. S...  \n",
       "2436  —pushes himself up from the chair beneath to r...  \n",
       "9622  Widow of CIA agent killed in 2009 Afghanistan ...  \n",
       "8999  As soon as God say yes they'll be screaming we...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = [\"location\"]\n",
    "text_feature = \"text\"  # Inputig as string rather than list\n",
    "categorical_feature = [\"keyword\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (CountVectorizer(stop_words=\"english\", max_features=3000), text_feature),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\",sparse=False), categorical_feature)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9096x3219 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 68911 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '01', ..., 'zip', 'zone', '하윤빈'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.named_transformers_[\"countvectorizer\"].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 DummyClassifier - Baseline score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.194 (+/- 0.016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.045 (+/- 0.004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dummy Classifier\n",
       "fit_time        0.194 (+/- 0.016)\n",
       "score_time      0.045 (+/- 0.004)\n",
       "test_precision  0.000 (+/- 0.000)\n",
       "test_f1         0.000 (+/- 0.000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_pipe = make_pipeline(preprocessor, DummyClassifier())\n",
    "\n",
    "results[\"Dummy Classifier\"] = mean_std_cross_val_scores(\n",
    "    dummy_pipe, X_train, y_train, scoring=scoring_metrics\n",
    ")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Logistic regression\n",
    "\n",
    "Now we try logistic regression classifier with the same scoring metrics and default hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.194 (+/- 0.016)</td>\n",
       "      <td>0.258 (+/- 0.016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.045 (+/- 0.004)</td>\n",
       "      <td>0.039 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.771 (+/- 0.027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.619 (+/- 0.026)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dummy Classifier Logistic Regression\n",
       "fit_time        0.194 (+/- 0.016)   0.258 (+/- 0.016)\n",
       "score_time      0.045 (+/- 0.004)   0.039 (+/- 0.007)\n",
       "test_precision  0.000 (+/- 0.000)   0.771 (+/- 0.027)\n",
       "test_f1         0.000 (+/- 0.000)   0.619 (+/- 0.026)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe = make_pipeline(preprocessor, LogisticRegression())\n",
    "results[\"Logistic Regression\"] = mean_std_cross_val_scores(\n",
    "    lr_pipe, X_train, y_train, scoring=scoring_metrics\n",
    ")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Hyperparameter optimization \n",
    "\n",
    "We jointly tune hyperparameters of logistic regression and `CountVectorizer`and report the best hyperparameter values and best cross-validation scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('countvectorizer',\n",
       "                                                                               CountVectorizer(max_features=3000,\n",
       "                                                                                               stop_words='english'),\n",
       "                                                                               'text'),\n",
       "                                                                              ('onehotencoder',\n",
       "                                                                               OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                             sparse=False),\n",
       "                                                                               ['keyword'])])),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'columntransformer__countvectorizer__max_features': array([1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]),\n",
       "                                        'logisticregression__C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                                        'logisticregression__class_weight': ['balanced',\n",
       "                                                                             None]},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    \"logisticregression__C\": np.logspace(-2, 2, 5),\n",
    "    \"logisticregression__class_weight\": [\"balanced\", None],\n",
    "    \"columntransformer__countvectorizer__max_features\": np.linspace(\n",
    "        1000, 5000, 9, dtype=int\n",
    "    ),\n",
    "}\n",
    "\n",
    "hyper_opt = RandomizedSearchCV(\n",
    "    estimator=lr_pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    scoring=\"f1\",\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "hyper_opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__class_weight': 'balanced',\n",
       " 'logisticregression__C': 0.1,\n",
       " 'columntransformer__countvectorizer__max_features': 5000}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best f1 score is 0.643.\n"
     ]
    }
   ],
   "source": [
    "print(f\"best f1 score is {round(hyper_opt.best_score_, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7: Feature engineering\n",
    "\n",
    "In this section we will be extracting out own features that might be useful for this prediction task. \n",
    "\n",
    "The code below adds some very basic length-related and sentiment features. We will be using a popular library called `nltk` for this section.\n",
    "\n",
    "1. We run the code below which creates three new features: \n",
    "    - Relative character length in the tweet. \n",
    "    - Number of words in the tweet.\n",
    "    - Sentiment of the tweet. In particular, we'll be using a metric called \"compound score\" representing the sentiment in the given tweet. (A score of -1 corresponds to most extreme negative and a score of +1 corresponds to most extreme positive.) This score is extracted using [Vader lexicon](https://github.com/cjhutto/vaderSentiment). Here we are using some pre-trained model to extract sentiment expressed in the tweets. Below I am showing you a couple of examples of using this pre-trained model for getting sentiment information on some random sentences. \n",
    "\n",
    "Below I am showing couple of examples from [Vader lexicon](https://github.com/cjhutto/vaderSentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\artan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\artan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.431}\n"
     ]
    }
   ],
   "source": [
    "s = \"Not bad at all.\"\n",
    "print(sid.polarity_scores(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.327, 'neu': 0.579, 'pos': 0.094, 'compound': -0.7042}\n"
     ]
    }
   ],
   "source": [
    "s = \"The plot was good, but the characters are uncompelling and the dialog is not great.\"\n",
    "print(sid.polarity_scores(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_length(text, TWITTER_ALLOWED_CHARS=280.0):\n",
    "    \"\"\"\n",
    "    Returns the relative length of text.\n",
    "\n",
    "    Parameters:\n",
    "    ------\n",
    "    text: (str)\n",
    "    the input text\n",
    "\n",
    "    Keyword arguments:\n",
    "    ------\n",
    "    TWITTER_ALLOWED_CHARS: (float)\n",
    "    the denominator for finding relative length\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    relative length of text: (float)\n",
    "\n",
    "    \"\"\"\n",
    "    return len(text) / TWITTER_ALLOWED_CHARS\n",
    "\n",
    "\n",
    "def get_length_in_words(text):\n",
    "    \"\"\"\n",
    "    Returns the length of the text in words.\n",
    "\n",
    "    Parameters:\n",
    "    ------\n",
    "    text: (str)\n",
    "    the input text\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    length of tokenized text: (int)\n",
    "\n",
    "    \"\"\"\n",
    "    return len(nltk.word_tokenize(text))\n",
    "\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Returns the compound score representing the sentiment of the given text: -1 (most extreme negative) and +1 (most extreme positive)\n",
    "    The compound score is a normalized score calculated by summing the valence scores of each word in the lexicon.\n",
    "\n",
    "    Parameters:\n",
    "    ------\n",
    "    text: (str)\n",
    "    the input text\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    sentiment of the text: (str)\n",
    "    \"\"\"\n",
    "    scores = sid.polarity_scores(text)\n",
    "    return scores[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(n_words=train_df[\"text\"].apply(get_length_in_words))\n",
    "train_df = train_df.assign(vader_sentiment=train_df[\"text\"].apply(get_sentiment))\n",
    "train_df = train_df.assign(rel_char_len=train_df[\"text\"].apply(get_relative_length))\n",
    "\n",
    "test_df = test_df.assign(n_words=test_df[\"text\"].apply(get_length_in_words))\n",
    "test_df = test_df.assign(vader_sentiment=test_df[\"text\"].apply(get_sentiment))\n",
    "test_df = test_df.assign(rel_char_len=test_df[\"text\"].apply(get_relative_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also for experiment I am creating some extra features. I am extracting whether a news agency has been mentioned in the tweet by seeing if there is a link (http) to news agency. I have also checked if a hashtag has been used to make a certain news a hashtag. Also, as an Iranian there has always been disaster associated with the name Iran through recent history. I will give this a try to see if I can find something sensible.  \n",
    "> Note: As long as the created features are derived by applying a function on individual row and not the rest of the column we are not violating the Golden rule. For the case of this section, since the n_words, vader sentiment, and rel_char_len are applied on single values not considering the rest of the observations, we are not violating the golden rule (i.e. leaking of the data to the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>n_words</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>rel_char_len</th>\n",
       "      <th>news_agency</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>Iran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>debris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unfortunately, both plans fail as the 3 are im...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.7650</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>crash</td>\n",
       "      <td>SLC</td>\n",
       "      <td>I hope this causes Bernie to crash and bern. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.5697</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>collide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>—pushes himself up from the chair beneath to r...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.439286</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Widow of CIA agent killed in 2009 Afghanistan ...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.9460</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>screaming</td>\n",
       "      <td>Azania</td>\n",
       "      <td>As soon as God say yes they'll be screaming we...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.203571</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword location  \\\n",
       "3289          debris      NaN   \n",
       "2672           crash      SLC   \n",
       "2436         collide      NaN   \n",
       "9622  suicide%20bomb      NaN   \n",
       "8999       screaming   Azania   \n",
       "\n",
       "                                                   text  target  n_words  \\\n",
       "3289  Unfortunately, both plans fail as the 3 are im...       0       22   \n",
       "2672  I hope this causes Bernie to crash and bern. S...       0       18   \n",
       "2436  —pushes himself up from the chair beneath to r...       0       21   \n",
       "9622  Widow of CIA agent killed in 2009 Afghanistan ...       1       20   \n",
       "8999  As soon as God say yes they'll be screaming we...       0       14   \n",
       "\n",
       "      vader_sentiment  rel_char_len  news_agency  hashtag   Iran  \n",
       "3289          -0.7650      0.425000        False    False  False  \n",
       "2672          -0.5697      0.267857         True    False  False  \n",
       "2436           0.0000      0.439286         True    False  False  \n",
       "9622          -0.9460      0.428571         True    False  False  \n",
       "8999           0.2960      0.203571        False    False  False  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"news_agency\"] = train_df[\"text\"].apply(lambda x: \"http\" in x or \"news\" in x)\n",
    "train_df[\"hashtag\"] = train_df[\"text\"].apply(lambda x: \"#\" in x)\n",
    "train_df[\"Iran\"] = train_df[\"text\"].apply(lambda x: \"iran\" in x.lower())\n",
    "\n",
    "test_df[\"news_agency\"] = test_df[\"text\"].apply(lambda x: \"http\" in x)\n",
    "test_df[\"hashtag\"] = test_df[\"text\"].apply(lambda x: \"#\" in x)\n",
    "test_df[\"Iran\"] = test_df[\"text\"].apply(lambda x: \"iran\" in x.lower())\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Pipeline with all features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = train_df.drop(\"target\", axis=1)\n",
    "y_train_new = train_df[\"target\"]\n",
    "\n",
    "X_test_new = test_df.drop(\"target\", axis=1)\n",
    "y_test_new = test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feature = \"text\"\n",
    "binary_features = [\"news_agency\", \"hashtag\", \"Iran\"]\n",
    "categorical_features = [\"keyword\"]\n",
    "numeric_feature = [\"n_words\"]\n",
    "passthrough = [\"vader_sentiment\", \"rel_char_len\"]\n",
    "drop_feature = [\"location\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_preprocessor = make_column_transformer(\n",
    "    (\n",
    "        CountVectorizer(\n",
    "            stop_words=\"english\",\n",
    "            max_features=hyper_opt.best_params_[\n",
    "                \"columntransformer__countvectorizer__max_features\"\n",
    "            ],\n",
    "        ),\n",
    "        text_feature,\n",
    "    ),\n",
    "    (OneHotEncoder(drop=\"if_binary\"), binary_features),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    (StandardScaler(), numeric_feature),\n",
    "    (\"passthrough\", passthrough),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__class_weight': 'balanced',\n",
       " 'logisticregression__C': 0.1,\n",
       " 'columntransformer__countvectorizer__max_features': 5000}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_pipeline = make_pipeline(\n",
    "    NLP_preprocessor,\n",
    "    LogisticRegression(\n",
    "        C=hyper_opt.best_params_[\"logisticregression__C\"],\n",
    "        class_weight=hyper_opt.best_params_[\"logisticregression__class_weight\"],\n",
    "        max_iter=300\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time          0.246 (+/- 0.008)\n",
       "score_time        0.042 (+/- 0.007)\n",
       "test_precision    0.589 (+/- 0.011)\n",
       "test_f1           0.654 (+/- 0.010)\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_cross_val_scores(\n",
    "    NLP_pipeline,\n",
    "    X_train_new,\n",
    "    y_train_new,\n",
    "    scoring=scoring_metrics,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Interpretation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see slight improvement on the f1 score but not much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('countvectorizer',\n",
       "                                                  CountVectorizer(max_features=5000,\n",
       "                                                                  stop_words='english'),\n",
       "                                                  'text'),\n",
       "                                                 ('onehotencoder-1',\n",
       "                                                  OneHotEncoder(drop='if_binary'),\n",
       "                                                  ['news_agency', 'hashtag',\n",
       "                                                   'Iran']),\n",
       "                                                 ('onehotencoder-2',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['keyword']),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['n_words']),\n",
       "                                                 ('passthrough', 'passthrough',\n",
       "                                                  ['vader_sentiment',\n",
       "                                                   'rel_char_len'])])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
       "                                    max_iter=300))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_pipeline.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = (\n",
    "    NLP_pipeline.named_steps[\"columntransformer\"]\n",
    "    .named_transformers_[\"countvectorizer\"]\n",
    "    .get_feature_names_out()\n",
    "    .tolist()\n",
    ")\n",
    "keyword_features = (\n",
    "    NLP_pipeline.named_steps[\"columntransformer\"]\n",
    "    .named_transformers_[\"onehotencoder-2\"]\n",
    "    .get_feature_names_out()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "column_names = (\n",
    "    text_features + binary_features + keyword_features + numeric_feature + passthrough\n",
    ")\n",
    "\n",
    "coefficients = NLP_pipeline.named_steps[\"logisticregression\"].coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>rel_char_len</td>\n",
       "      <td>1.269627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>1.020694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>keyword_windstorm</td>\n",
       "      <td>0.918887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>rescued</td>\n",
       "      <td>0.900307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>died</td>\n",
       "      <td>0.896980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>road</td>\n",
       "      <td>0.876581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>collision</td>\n",
       "      <td>0.869327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>ukrainian</td>\n",
       "      <td>0.838220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>survived</td>\n",
       "      <td>0.834366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>hit</td>\n",
       "      <td>0.815764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  coefficient\n",
       "5224       rel_char_len     1.269627\n",
       "4463       thunderstorm     1.020694\n",
       "5216  keyword_windstorm     0.918887\n",
       "3623            rescued     0.900307\n",
       "1144               died     0.896980\n",
       "3678               road     0.876581\n",
       "776           collision     0.869327\n",
       "4625          ukrainian     0.838220\n",
       "4295           survived     0.834366\n",
       "1948                hit     0.815764"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({\"feature\": column_names, \"coefficient\": coefficients}).sort_values(\"coefficient\", ascending=False)\n",
    "coef_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>want</td>\n",
       "      <td>-0.493764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>cause</td>\n",
       "      <td>-0.505274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>keyword_demolition</td>\n",
       "      <td>-0.530712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>keyword_blazing</td>\n",
       "      <td>-0.532947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>keyword_collapse</td>\n",
       "      <td>-0.554750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>heart</td>\n",
       "      <td>-0.563255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>love</td>\n",
       "      <td>-0.607777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>like</td>\n",
       "      <td>-0.765922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>vader_sentiment</td>\n",
       "      <td>-0.822291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>don</td>\n",
       "      <td>-0.857552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  coefficient\n",
       "4801                want    -0.493764\n",
       "644                cause    -0.505274\n",
       "5069  keyword_demolition    -0.530712\n",
       "5022     keyword_blazing    -0.532947\n",
       "5048    keyword_collapse    -0.554750\n",
       "1897               heart    -0.563255\n",
       "2551                love    -0.607777\n",
       "2480                like    -0.765922\n",
       "5223     vader_sentiment    -0.822291\n",
       "1216                 don    -0.857552"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above top ranking positive and negative coefficients, we can see that most of them make sense.\n",
    "Below are the coefficients for the three columns that I added. Two of them have high positive coefficients, but the feature capturing the news agencies actually has a negative coefficient which might probably be due to the fact that not all news are disaster related (or that I have not used the proper method to extract news related tweets!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Resultant coefficient from added feature `Iran`:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>Iran</td>\n",
       "      <td>0.495746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  coefficient\n",
       "5002    Iran     0.495746"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.query(\"feature == 'Iran'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Resultant coefficient from added feature `hashtag`:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>0.404291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  coefficient\n",
       "5001  hashtag     0.404291"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.query(\"feature == 'hashtag'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Resultant coefficient from added feature `news_agency`:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>news_agency</td>\n",
       "      <td>-0.225947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  coefficient\n",
       "5000  news_agency    -0.225947"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.query(\"feature == 'news_agency'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 Test results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score for the test data is 0.68.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "test_score = f1_score(y_test_new, NLP_pipeline.predict(X_test_new))\n",
    "print(f\"The f1 score for the test data is {round(test_score, 2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Dataset for Feature Selection\n",
    "<hr>\n",
    "\n",
    "In the following exercises, we'll be using [`sklearn`'s boston housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) to do some feature selection. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_housing = load_boston()\n",
    "print(boston_housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df = pd.DataFrame(boston_housing.data, columns=boston_housing.feature_names)\n",
    "boston_df[\"target\"] = boston_housing.target\n",
    "train_df, test_df = train_test_split(boston_df, test_size=0.2, random_state=2)\n",
    "\n",
    "X_train, y_train = train_df.drop(columns=[\"target\"]), train_df[\"target\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"target\"]), test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Feature importances and feature selection \n",
    "<hr>\n",
    "\n",
    "We'll briefly explore feature importances, recursive feature elimination, adding polynomial features in a pipeline, and forward/backward selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Feature importance\n",
    "\n",
    "The following code shows the coefficients learned by `RidgeCV` on the Boston housing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.107895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.039087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.020005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>3.138096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-15.339384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.640792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.008323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.367897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.321224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.011728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-1.021972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.011694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.560337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefficient\n",
       "CRIM       -0.107895\n",
       "ZN          0.039087\n",
       "INDUS      -0.020005\n",
       "CHAS        3.138096\n",
       "NOX       -15.339384\n",
       "RM          3.640792\n",
       "AGE         0.008323\n",
       "DIS        -1.367897\n",
       "RAD         0.321224\n",
       "TAX        -0.011728\n",
       "PTRATIO    -1.021972\n",
       "B           0.011694\n",
       "LSTAT      -0.560337"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv = RidgeCV()\n",
    "lrcv.fit(X_train, y_train)\n",
    "pd.DataFrame(data=lrcv.coef_, index=X_train.columns, columns=[\"coefficient\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 `RFECV` \n",
    "\n",
    "We'll explore recursive feature elimination for feature selection. The code below defines a pipeline with feature selection incorporated in it. `RFECV` is used for feature selection in the pipeline; it uses cross-validation to decide how many features to select. The selected features are passed to `RidgeCV`, which has built-in cross-validation to tune the `alpha` hyperparameter.  \n",
    "\n",
    "We will see how many features have been selected by `RFECV` using the `n_features_` attribute of the `RFECV` step from the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rfe_ridgecv = make_pipeline(StandardScaler(), RFECV(Ridge(), cv=10), RidgeCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.160 (+/- 0.023)\n",
       "score_time     0.006 (+/- 0.009)\n",
       "test_score     0.704 (+/- 0.077)\n",
       "train_score    0.730 (+/- 0.017)\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_score = mean_std_cross_val_scores(\n",
    "    pipe_rfe_ridgecv, X_train, y_train, cv=5, return_train_score=True\n",
    ")\n",
    "rfe_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.704 (+/- 0.077)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_score[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('rfecv', RFECV(cv=10, estimator=Ridge())),\n",
       "                ('ridgecv', RidgeCV(alphas=array([ 0.1,  1. , 10. ])))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rfe_ridgecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rfe_ridgecv.named_steps['rfecv'].n_features_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rfe_ridgecv.named_steps[\"rfecv\"].n_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: `PolynomialFeatures` + `RFECV`\n",
    "\n",
    "We add one more step to the pipeline above, `PolynomialFeatures()`, for extracting polynomial features. We then carry out cross-validation using the pipeline and report the mean validation scores.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_pipe = make_pipeline(\n",
    "    StandardScaler(), PolynomialFeatures(degree=3), RFECV(Ridge(), cv=10), RidgeCV()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       21.906 (+/- 1.359)\n",
       "score_time      0.001 (+/- 0.001)\n",
       "test_score      0.845 (+/- 0.058)\n",
       "train_score     0.925 (+/- 0.017)\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_score = mean_std_cross_val_scores(\n",
    "    poly_pipe, X_train, y_train, cv=5, return_train_score=True\n",
    ")\n",
    "poly_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mean crossvalidation R2 score improved a lot from 0.7 to 0.84. This is mainly because of the higher number of features and the fact that some of these features have had a polynomial shape and once transformed to third degree polynomial, we have been able to fit them better in our regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Selected Features with Polynomial \n",
    "\n",
    "We will see how many total features there will be before and after applying `PolynomialFeatures` transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('polynomialfeatures', PolynomialFeatures(degree=3)),\n",
       "                ('rfecv', RFECV(cv=10, estimator=Ridge())),\n",
       "                ('ridgecv', RidgeCV(alphas=array([ 0.1,  1. , 10. ])))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_pipe.named_steps[\"rfecv\"].n_features_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_pipe.named_steps[\"rfecv\"].n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x6', 'x7', 'x8', 'x35', 'x63', 'x64', 'x74', 'x76', 'x84', 'x89',\n",
       "       'x90', 'x95', 'x99', 'x134', 'x145', 'x167', 'x169', 'x187',\n",
       "       'x195', 'x251', 'x284', 'x336', 'x403', 'x420', 'x421', 'x423',\n",
       "       'x424', 'x453', 'x463', 'x484', 'x496', 'x505', 'x514', 'x515',\n",
       "       'x518', 'x524', 'x525', 'x541', 'x542', 'x544'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_pipe.named_steps[\"rfecv\"].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5: `PolynomialFeatures` + backward selection\n",
    "\n",
    "We now define a pipeline with `StandardScaler()`, `PolynomialFeatures()`, and backward feature selection (`SequentialFeatureSelector` with `Ridge` and direction `backward`) and report cross-validation scores.  \n",
    "> In `SequentialFeatureSelector` (SFS) with backward direction we start with a set of all features, sequentially find the one feature that has the least effect on the maximization of a cross-validation score and greedily remove features from the set. On the other hand, he goal of RFE is to select features by recursively considering smaller and smaller sets of features instead of just one feature removed by SFS. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute. Then, the least important features are removed from current set of features. That procedure is recursively repeated on the new set until the desired number of features to select is eventually reached. For this reason RFE is very slower than SFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_seq_pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(),\n",
    "    SequentialFeatureSelector(Ridge(), direction=\"backward\", n_jobs=-1),\n",
    "    RidgeCV(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       52.778 (+/- 2.778)\n",
       "score_time      0.000 (+/- 0.000)\n",
       "test_score      0.796 (+/- 0.064)\n",
       "train_score     0.922 (+/- 0.006)\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_cross_val_scores(poly_seq_pipe, X_train, y_train, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(direction='backward', estimator=Ridge(), n_jobs=-1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_seq_pipe.named_steps['sequentialfeatureselector']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean crossvalidation score from this pipeline with backward selection is less than the ones from RFECV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
