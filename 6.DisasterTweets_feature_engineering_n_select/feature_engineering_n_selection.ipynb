{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 573 - Feature and Model Selection\n",
    "\n",
    "# Lab 2: Feature engineering, feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "- [Submission instructions](#si) (4%)\n",
    "- [Exercise 1: Feature engineering](#1) (74%)\n",
    "- [(Optional) Exercise 2: Change of basis](#2) \n",
    "- [Exercise 3: Recursive feature elimination and forward selection](#3) (22%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "rubric={mechanics:4}\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. To submit this assignment, follow the instructions below:\n",
    "\n",
    "- **Please add a link to your GitHub repository here: [LINK TO REPO](https://github.ubc.ca/mds-2021-22/DSCI_573_lab2_azandian)**\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n",
    "- Make at least three commits in your lab's GitHub repository.\n",
    "- Push the final .ipynb file with your solutions to your GitHub repository for this lab.\n",
    "- Upload the .ipynb file to Gradescope.\n",
    "- If the .ipynb file is too big or doesn't render on Gradescope for some reason, also upload a pdf or html in addition to the .ipynb. \n",
    "- Make sure that your plots/output are rendered properly in Gradescope.\n",
    "\n",
    "> [Here](https://github.com/UBC-MDS/public/tree/master/rubric) you will find the description of each rubric used in MDS.\n",
    "\n",
    "> As usual, do not push the data to the repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, RidgeCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    ShuffleSplit,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    PolynomialFeatures,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Feature engineering <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "One of the most important aspects which influences performance of machine learning models is the features used to represent the problem. If your underlying representation is bad whatever fancy model you use is not going to help. With a better feature representation, a simple and a more interpretable model is likely to perform reasonably well. \n",
    "\n",
    "**Feature engineering** is the process of transforming raw data into features that better represent the underlying problem to the predictive models. \n",
    "\n",
    "In this exercise we'll engineer our own features on [the Disaster Tweets dataset](https://www.kaggle.com/vstepanenko/disaster-tweets). \n",
    "\n",
    "Note that coming up with features is difficult, time-consuming, and requires expert knowledge. The purpose of this exercise is to give you a little taste of feature engineering, which you are likely to be doing in your career as a data scientist or a machine learning practitioner. In this exercise, since we'll be using simplistic features, you might not get better scores with your engineered features, and that's fine. The purpose here is to make you familiar with the process of feature engineering rather than getting the best scores. \n",
    "\n",
    "As usual, download the dataset, unzip it and save it in your lab folder. As usual, do not push it into the repository. \n",
    "\n",
    "The code below reads the data CSV assuming that the file is stored as `tweets.csv` in your lab folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>debris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unfortunately, both plans fail as the 3 are im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>crash</td>\n",
       "      <td>SLC</td>\n",
       "      <td>I hope this causes Bernie to crash and bern. S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>collide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>—pushes himself up from the chair beneath to r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Widow of CIA agent killed in 2009 Afghanistan ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>screaming</td>\n",
       "      <td>Azania</td>\n",
       "      <td>As soon as God say yes they'll be screaming we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword location  \\\n",
       "3289          debris      NaN   \n",
       "2672           crash      SLC   \n",
       "2436         collide      NaN   \n",
       "9622  suicide%20bomb      NaN   \n",
       "8999       screaming   Azania   \n",
       "\n",
       "                                                   text  target  \n",
       "3289  Unfortunately, both plans fail as the 3 are im...       0  \n",
       "2672  I hope this causes Bernie to crash and bern. S...       0  \n",
       "2436  —pushes himself up from the chair beneath to r...       0  \n",
       "9622  Widow of CIA agent killed in 2009 Afghanistan ...       1  \n",
       "8999  As soon as God say yes they'll be screaming we...       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweets.csv\", usecols=[\"keyword\", \"text\", \"target\", \"location\"])\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=2)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(columns=[\"target\"]), train_df[\"target\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"target\"]), test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 \n",
    "rubric={reasoning:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. What is the prediction problem that we are trying to solve here? State in your own words. (One sentence is enough.) \n",
    "2. Do we have class imbalance? If yes, do we need to deal with it? Briefly explain. \n",
    "3. What metric(s) would you use in this case? Accordingly, define the `scoring_metrics` below. \n",
    "\n",
    "> You may decide to use more than one metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We are trying to predict whether the content of a tweet is a real disaster or not.\n",
    "2. According to the below calculations we see that there is a class imbalance. We definitely need to deal with the class imbalance because the difference between 81% and 18% seems large.\n",
    "3. Assuming that we use this for a real situations (and we want to send out forces to help victims before it is too late), it is very important to have a high precision meaning that we want to know the number of tweets that we correctly labeled \"disaster\" from the list of tweets that are reporting a disaster in reality. I will also be using f1 score to make sure I don't get really low recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.812995\n",
       "1    0.187005\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metrics = [\"precision\", \"f1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The location feature\n",
    "rubric={reasoning:6}\n",
    "\n",
    "The location feature seems quite messy. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify at least two challenges that would be involved in encoding the location feature. \n",
    "2. It is fine if you drop this feature in this assignment. But if you have to include it, how you might encode it? You don't have to write any code. Just pointing out challenges and providing some reasonable ideas should be fine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first challenge would be the high ratio of NA's and the second is that this looks like a free text without any structure. For example in some examples name of a city has been used where in other observations it is a country or state. Also, there is a use of emoticons which should be translated to text.\n",
    "2. More than a third of the values are unique. In order to reduce the number of unique values, I will use some wrangling and built-in string match functionality of pandas to see if I can replace the name of the cities and states with countries (using list of cities and countries from another dataframe). I will also use a library like spacymoji to translate emoji's to text in order to see if I can get name of any flags translated to country names. After extracting as much country as I could, I will use OneHotEncoder and only provide the categories of the 192 countries. Instead of the last step, I could alternatively use CountVectorizer and use an `n-gram range` of 1 to 3 (because name of some countries is comprised of multiple names) and use `min_df` to ignore the locations that have lower frequency that the threshold that I specify in order to remove the ones that only appear for one or two times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['location'].nunique()\n",
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'SLC', 'Azania', 'United States',\n",
       "       'Amphoe Mueang Nakhon Ratchasim', 'Accra, Ghana', 'Lagos, Nigeria',\n",
       "       'Rohnert Park, CA', 'Brighton', 'Hell,Hades,Mictlan,Tartarus'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['location'].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States                     80\n",
       "Australia                         68\n",
       "London, England                   66\n",
       "UK                                62\n",
       "India                             60\n",
       "                                  ..\n",
       "Arizona City, AZ                   1\n",
       "Yorkshire & Scotland               1\n",
       "th: hakuna matata                  1\n",
       "Tacloban City, Eastern Visayas     1\n",
       "Greater Manchester                 1\n",
       "Name: location, Length: 3746, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0% of the values in the location column are missing.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{round(100 * sum(X_train['location'].isna()) / X_train.shape[0], 1)}% of the values in the location column are missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Identifying feature types\n",
    "rubric={accuracy:6,reasoning:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "In preparation for building a classifier, identify different feature types and set up a column transformer that performs whatever feature transformations you deem sensible. This can include dropping features if you think they are not helpful. In each case, briefly explain your rationale with 1-2 sentences. \n",
    "\n",
    "> Hint: Remember that for `CountVectorizer` transformer, you need to pass a 1-D array or a pandas.Series. So in a column transformer, you pass a string rather than a list of features for this transformer. [Here](https://pages.github.ubc.ca/mds-2021-22/DSCI_571_sup-learn-1_students/lectures/05_text-feats.html#demo-of-incorporating-text-features) you'll find an example of incorporating text column in a column transformer. \n",
    "\n",
    "> It's fine if you drop the location feature for this assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I am dropping the location column as it does not provide any useful information and is in a free text format.\n",
    "- I will be watching that my number of features won't grow more than my observations (m < n). I will use a Countvectorizer for the `text` column and will use max_feature to limit the number of columns. If not specified, it will give me more than 23,000 feature columns.\n",
    "- For the `keyword` column I will use a OneHotEncoder as it is a categorical column with 200 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>debris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unfortunately, both plans fail as the 3 are im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>crash</td>\n",
       "      <td>SLC</td>\n",
       "      <td>I hope this causes Bernie to crash and bern. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>collide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>—pushes himself up from the chair beneath to r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Widow of CIA agent killed in 2009 Afghanistan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>screaming</td>\n",
       "      <td>Azania</td>\n",
       "      <td>As soon as God say yes they'll be screaming we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword location  \\\n",
       "3289          debris      NaN   \n",
       "2672           crash      SLC   \n",
       "2436         collide      NaN   \n",
       "9622  suicide%20bomb      NaN   \n",
       "8999       screaming   Azania   \n",
       "\n",
       "                                                   text  \n",
       "3289  Unfortunately, both plans fail as the 3 are im...  \n",
       "2672  I hope this causes Bernie to crash and bern. S...  \n",
       "2436  —pushes himself up from the chair beneath to r...  \n",
       "9622  Widow of CIA agent killed in 2009 Afghanistan ...  \n",
       "8999  As soon as God say yes they'll be screaming we...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = [\"location\"]\n",
    "text_feature = \"text\"  # Inputig as string rather than list\n",
    "categorical_feature = [\"keyword\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (CountVectorizer(stop_words=\"english\", max_features=3000), text_feature),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\",sparse=False), categorical_feature)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9096x3219 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 68911 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '01', ..., 'zip', 'zone', '하윤빈'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.named_transformers_[\"countvectorizer\"].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 DummyClassifier\n",
    "rubric={accuracy:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Report cross-validation scores for `DummyClassifier` using `scoring_metrics` you defined in 1.1. \n",
    "\n",
    "> You might want to use the `results` dictionary and `mean_std_cross_val_scores` function below to organize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.172 (+/- 0.011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.043 (+/- 0.008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dummy Classifier\n",
       "fit_time        0.172 (+/- 0.011)\n",
       "score_time      0.043 (+/- 0.008)\n",
       "test_precision  0.000 (+/- 0.000)\n",
       "test_f1         0.000 (+/- 0.000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_pipe = make_pipeline(preprocessor, DummyClassifier())\n",
    "\n",
    "results[\"Dummy Classifier\"] = mean_std_cross_val_scores(\n",
    "    dummy_pipe, X_train, y_train, scoring=scoring_metrics\n",
    ")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Logistic regression\n",
    "rubric={accuracy:3}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Now try logistic regression classifier with the same scoring metrics and default hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy Classifier</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.172 (+/- 0.011)</td>\n",
       "      <td>0.256 (+/- 0.017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.043 (+/- 0.008)</td>\n",
       "      <td>0.041 (+/- 0.008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.771 (+/- 0.027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.619 (+/- 0.026)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dummy Classifier Logistic Regression\n",
       "fit_time        0.172 (+/- 0.011)   0.256 (+/- 0.017)\n",
       "score_time      0.043 (+/- 0.008)   0.041 (+/- 0.008)\n",
       "test_precision  0.000 (+/- 0.000)   0.771 (+/- 0.027)\n",
       "test_f1         0.000 (+/- 0.000)   0.619 (+/- 0.026)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe = make_pipeline(preprocessor, LogisticRegression())\n",
    "results[\"Logistic Regression\"] = mean_std_cross_val_scores(\n",
    "    lr_pipe, X_train, y_train, scoring=scoring_metrics\n",
    ")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Hyperparameter optimization \n",
    "rubric={accuracy:7}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Jointly tune hyperparameters of logistic regression and `CountVectorizer`. Some options for hyperparameters are:   \n",
    "    - `C` of logistic regression\n",
    "    - `class_weight` of logistic regression\n",
    "    - `max_features` of `CountVectorizer`\n",
    "2. Report the best hyperparameter values and best cross-validation scores.\n",
    "\n",
    "> Hint: You can access `max_features` of `CounVectorizer` of a `ColumnTransformer` object as: `columntransformer__countvectorizer__max_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('countvectorizer',\n",
       "                                                                               CountVectorizer(max_features=3000,\n",
       "                                                                                               stop_words='english'),\n",
       "                                                                               'text'),\n",
       "                                                                              ('onehotencoder',\n",
       "                                                                               OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                             sparse=False),\n",
       "                                                                               ['keyword'])])),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'columntransformer__countvectorizer__max_features': array([1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]),\n",
       "                                        'logisticregression__C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                                        'logisticregression__class_weight': ['balanced',\n",
       "                                                                             None]},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    \"logisticregression__C\": np.logspace(-2, 2, 5),\n",
    "    \"logisticregression__class_weight\": [\"balanced\", None],\n",
    "    \"columntransformer__countvectorizer__max_features\": np.linspace(\n",
    "        1000, 5000, 9, dtype=int\n",
    "    ),\n",
    "}\n",
    "\n",
    "hyper_opt = RandomizedSearchCV(\n",
    "    estimator=lr_pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    scoring=\"f1\",\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "hyper_opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__class_weight': 'balanced',\n",
       " 'logisticregression__C': 1.0,\n",
       " 'columntransformer__countvectorizer__max_features': 5000}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best precision score is 0.65.\n"
     ]
    }
   ],
   "source": [
    "print(f\"best precision score is {round(hyper_opt.best_score_, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.7: Feature engineering\n",
    "rubric={accuracy:10,reasoning:8}\n",
    "\n",
    "Is it possible to further improve the scores? How about adding new features based on our intuitions? In this exercise, you will be extracting your own features that might be useful for this prediction task. In other words, you will carry out **feature engineering**. \n",
    "\n",
    "The code below adds some very basic length-related and sentiment features. We will be using a popular library called `nltk` for this exercise. If you have successfully created the course `conda` environment on your machine, you should already have this package in the environment.  \n",
    "\n",
    "**Your tasks:**\n",
    "1. Run the starter code below which creates three new features: \n",
    "    - Relative character length in the tweet. \n",
    "    - Number of words in the tweet.\n",
    "    - Sentiment of the tweet. In particular, we'll be using a metric called \"compound score\" representing the sentiment in the given tweet. (A score of -1 corresponds to most extreme negative and a score of +1 corresponds to most extreme positive.) This score is extracted using [Vader lexicon](https://github.com/cjhutto/vaderSentiment). In 571, we trained our own models for sentiment analysis. Here we are using some **pre-trained model** to extract sentiment expressed in the tweets. Below I am showing you a couple of examples of using using this pre-trained model for getting sentiment information on some random sentences. \n",
    "2. Extract at least two more features that you think might be relevant for prediction and store them as new columns in the train and test sets. Briefly explain your intuition on why these features might help the prediction task. \n",
    "3. Would it have been OK to create new columns directly in the original `df` instead of creating them separately for train and test splits? Would that be violation of the golden rule? \n",
    "\n",
    "> As I mentioned in the lecture, coming up with good features is not easy. It can be time consuming, as you need to think deeply about what representation would help the prediction problem. But please don't spend WAY too much time on this question. (Of course if you're having fun you're welcome to spend as much time as you want!) My suggestion would be coming up with some simple features first, getting the pipeline working, and completing the assignment. If you have time after submitting all your assignments, you can always come back to this question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\artan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\artan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.317, 'pos': 0.683, 'compound': 0.8225}\n"
     ]
    }
   ],
   "source": [
    "s = \"MDS students are smart, sweet, and funny.\"\n",
    "print(sid.polarity_scores(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.264, 'neu': 0.736, 'pos': 0.0, 'compound': -0.5106}\n"
     ]
    }
   ],
   "source": [
    "s = \"MDS students are tired because of all the hard work they have been doing.\"\n",
    "print(sid.polarity_scores(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_length(text, TWITTER_ALLOWED_CHARS=280.0):\n",
    "    \"\"\"\n",
    "    Returns the relative length of text.\n",
    "\n",
    "    Parameters:\n",
    "    ------\n",
    "    text: (str)\n",
    "    the input text\n",
    "\n",
    "    Keyword arguments:\n",
    "    ------\n",
    "    TWITTER_ALLOWED_CHARS: (float)\n",
    "    the denominator for finding relative length\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    relative length of text: (float)\n",
    "\n",
    "    \"\"\"\n",
    "    return len(text) / TWITTER_ALLOWED_CHARS\n",
    "\n",
    "\n",
    "def get_length_in_words(text):\n",
    "    \"\"\"\n",
    "    Returns the length of the text in words.\n",
    "\n",
    "    Parameters:\n",
    "    ------\n",
    "    text: (str)\n",
    "    the input text\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    length of tokenized text: (int)\n",
    "\n",
    "    \"\"\"\n",
    "    return len(nltk.word_tokenize(text))\n",
    "\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Returns the compound score representing the sentiment of the given text: -1 (most extreme negative) and +1 (most extreme positive)\n",
    "    The compound score is a normalized score calculated by summing the valence scores of each word in the lexicon.\n",
    "\n",
    "    Parameters:\n",
    "    ------\n",
    "    text: (str)\n",
    "    the input text\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    sentiment of the text: (str)\n",
    "    \"\"\"\n",
    "    scores = sid.polarity_scores(text)\n",
    "    return scores[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(n_words=train_df[\"text\"].apply(get_length_in_words))\n",
    "train_df = train_df.assign(vader_sentiment=train_df[\"text\"].apply(get_sentiment))\n",
    "train_df = train_df.assign(rel_char_len=train_df[\"text\"].apply(get_relative_length))\n",
    "\n",
    "test_df = test_df.assign(n_words=test_df[\"text\"].apply(get_length_in_words))\n",
    "test_df = test_df.assign(vader_sentiment=test_df[\"text\"].apply(get_sentiment))\n",
    "test_df = test_df.assign(rel_char_len=test_df[\"text\"].apply(get_relative_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>n_words</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>rel_char_len</th>\n",
       "      <th>news_agency</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>Iran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>debris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unfortunately, both plans fail as the 3 are im...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.7650</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>crash</td>\n",
       "      <td>SLC</td>\n",
       "      <td>I hope this causes Bernie to crash and bern. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.5697</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>collide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>—pushes himself up from the chair beneath to r...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.439286</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Widow of CIA agent killed in 2009 Afghanistan ...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.9460</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>screaming</td>\n",
       "      <td>Azania</td>\n",
       "      <td>As soon as God say yes they'll be screaming we...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.203571</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword location  \\\n",
       "3289          debris      NaN   \n",
       "2672           crash      SLC   \n",
       "2436         collide      NaN   \n",
       "9622  suicide%20bomb      NaN   \n",
       "8999       screaming   Azania   \n",
       "\n",
       "                                                   text  target  n_words  \\\n",
       "3289  Unfortunately, both plans fail as the 3 are im...       0       22   \n",
       "2672  I hope this causes Bernie to crash and bern. S...       0       18   \n",
       "2436  —pushes himself up from the chair beneath to r...       0       21   \n",
       "9622  Widow of CIA agent killed in 2009 Afghanistan ...       1       20   \n",
       "8999  As soon as God say yes they'll be screaming we...       0       14   \n",
       "\n",
       "      vader_sentiment  rel_char_len  news_agency  hashtag   Iran  \n",
       "3289          -0.7650      0.425000        False    False  False  \n",
       "2672          -0.5697      0.267857         True    False  False  \n",
       "2436           0.0000      0.439286         True    False  False  \n",
       "9622          -0.9460      0.428571         True    False  False  \n",
       "8999           0.2960      0.203571        False    False  False  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"news_agency\"] = train_df[\"text\"].apply(lambda x: \"http\" in x)\n",
    "train_df[\"hashtag\"] = train_df[\"text\"].apply(lambda x: \"#\" in x)\n",
    "train_df[\"Iran\"] = train_df[\"text\"].apply(lambda x: \"iran\" in x.lower())\n",
    "\n",
    "test_df[\"news_agency\"] = test_df[\"text\"].apply(lambda x: \"http\" in x)\n",
    "test_df[\"hashtag\"] = test_df[\"text\"].apply(lambda x: \"#\" in x)\n",
    "test_df[\"Iran\"] = test_df[\"text\"].apply(lambda x: \"iran\" in x.lower())\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_2. I am extracting whether a news agency has been mentioned in the tweet by seeing if there is a link (https) to news agency. I have also checked if a hashtag has been used to make a certain news a hashtag. Also, as an Iranian there has always been disaster associated with the name Iran through recent history. I will give this a try to see if it really makes sense._  \n",
    "_3. As long as the created features are derived by applying a function on individual row and not the rest of the column we are not violating the Golden rule. For the case of this exercise, since the n_words, vader sentiment, and rel_char_len are applied on single values not considering the rest of the observations, we are not violating the golden rule._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Pipeline with all features\n",
    "rubric={accuracy:6}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Define a new column transformer for your mixed feature types in your new data set with the features you have created above in 1.7.\n",
    "2. Define a pipeline with logistic regression, setting the hyperparameter values to the ones you found in 1.6. \n",
    "3. Report cross-validation scores with this new pipeline. \n",
    "\n",
    "> It's possible that you might get different hyperparameter values with these new features. In real life, you might have to go through a couple of iterations of hyperparameter tuning and feature engineering. But in this assignment, in the interest of time, we won't carry out hyperparameter optimization again after feature engineering.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = train_df.drop(\"target\", axis=1)\n",
    "y_train_new = train_df[\"target\"]\n",
    "\n",
    "X_test_new = test_df.drop(\"target\", axis=1)\n",
    "y_test_new = test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feature = \"text\"\n",
    "binary_features = [\"news_agency\", \"hashtag\", \"Iran\"]\n",
    "categorical_features = [\"keyword\"]\n",
    "numeric_feature = [\"n_words\"]\n",
    "passthrough = [\"vader_sentiment\", \"rel_char_len\"]\n",
    "drop_feature = [\"location\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_preprocessor = make_column_transformer(\n",
    "    (\n",
    "        CountVectorizer(\n",
    "            stop_words=\"english\",\n",
    "            max_features=hyper_opt.best_params_[\n",
    "                \"columntransformer__countvectorizer__max_features\"\n",
    "            ],\n",
    "        ),\n",
    "        text_feature,\n",
    "    ),\n",
    "    (OneHotEncoder(drop=\"if_binary\"), binary_features),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    (StandardScaler(), numeric_feature),\n",
    "    (\"passthrough\", passthrough),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__class_weight': 'balanced',\n",
       " 'logisticregression__C': 1.0,\n",
       " 'columntransformer__countvectorizer__max_features': 5000}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_pipeline = make_pipeline(\n",
    "    NLP_preprocessor,\n",
    "    LogisticRegression(\n",
    "        C=hyper_opt.best_params_[\"logisticregression__C\"],\n",
    "        class_weight=hyper_opt.best_params_[\"logisticregression__class_weight\"],\n",
    "        max_iter=300\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time          0.459 (+/- 0.027)\n",
       "score_time        0.071 (+/- 0.009)\n",
       "test_precision    0.624 (+/- 0.008)\n",
       "test_f1           0.658 (+/- 0.018)\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_cross_val_scores(\n",
    "    NLP_pipeline,\n",
    "    X_train_new,\n",
    "    y_train_new,\n",
    "    scoring=scoring_metrics,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Interpretation\n",
    "rubric={accuracy:10,reasoning:4}\n",
    "\n",
    "1. Do you see any improvements in the scores with the new features? If you do not see big improvements in scores with new features, that's OK. Do not get discouraged. Feature engineering is hard and requires domain expertise. The purpose of this exercise is to make you familiar to the process of extracting new features rather than getting the best scores. \n",
    "2. Show first few (e.g., first 10) most important features and their coefficients identified by the model. \n",
    "3. Examine the coefficients of the features we have extracted above. Do these coefficients align with your intuitions? Briefly explain. \n",
    "\n",
    "> Hint: You need to fit the pipeline in order to get feature names from your transformers. \n",
    "\n",
    "> Assuming that your pipeline is named `pipe_lr` and it's fitted, you can get the feature names created by `CountVectorizer` using the syntax below: \n",
    "\n",
    "```pipe_lr.named_steps[\"columntransformer\"].named_transformers_[\"countvectorizer\"].get_feature_names_out()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_1. We see slight improvement on the f1 score but not much._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('countvectorizer',\n",
       "                                                  CountVectorizer(max_features=5000,\n",
       "                                                                  stop_words='english'),\n",
       "                                                  'text'),\n",
       "                                                 ('onehotencoder-1',\n",
       "                                                  OneHotEncoder(drop='if_binary'),\n",
       "                                                  ['news_agency', 'hashtag',\n",
       "                                                   'Iran']),\n",
       "                                                 ('onehotencoder-2',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['keyword']),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['n_words']),\n",
       "                                                 ('passthrough', 'passthrough',\n",
       "                                                  ['vader_sentiment',\n",
       "                                                   'rel_char_len'])])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=300))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_pipeline.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = (\n",
    "    NLP_pipeline.named_steps[\"columntransformer\"]\n",
    "    .named_transformers_[\"countvectorizer\"]\n",
    "    .get_feature_names_out()\n",
    "    .tolist()\n",
    ")\n",
    "keyword_features = (\n",
    "    NLP_pipeline.named_steps[\"columntransformer\"]\n",
    "    .named_transformers_[\"onehotencoder-2\"]\n",
    "    .get_feature_names_out()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "column_names = (\n",
    "    text_features + binary_features + keyword_features + numeric_feature + passthrough\n",
    ")\n",
    "\n",
    "coefficients = NLP_pipeline.named_steps[\"logisticregression\"].coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>rel_char_len</td>\n",
       "      <td>2.417235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>2.263189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>keyword_windstorm</td>\n",
       "      <td>2.089528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>survived</td>\n",
       "      <td>2.079450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>influenza</td>\n",
       "      <td>1.966293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>road</td>\n",
       "      <td>1.941573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>ukrainian</td>\n",
       "      <td>1.894293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>rescued</td>\n",
       "      <td>1.866336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>died</td>\n",
       "      <td>1.858740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>dies</td>\n",
       "      <td>1.818639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  coefficient\n",
       "5224       rel_char_len     2.417235\n",
       "4463       thunderstorm     2.263189\n",
       "5216  keyword_windstorm     2.089528\n",
       "4295           survived     2.079450\n",
       "2116          influenza     1.966293\n",
       "3678               road     1.941573\n",
       "4625          ukrainian     1.894293\n",
       "3623            rescued     1.866336\n",
       "1144               died     1.858740\n",
       "1145               dies     1.818639"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({\"feature\": column_names, \"coefficient\": coefficients}).sort_values(\"coefficient\", ascending=False)\n",
    "coef_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>waiting</td>\n",
       "      <td>-1.306888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>mean</td>\n",
       "      <td>-1.320104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>keyword_blazing</td>\n",
       "      <td>-1.353575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>don</td>\n",
       "      <td>-1.386778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>heart</td>\n",
       "      <td>-1.408779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>keyword_demolition</td>\n",
       "      <td>-1.416988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ass</td>\n",
       "      <td>-1.456028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>trudeau</td>\n",
       "      <td>-1.456181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>love</td>\n",
       "      <td>-1.521717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>keyword_collapse</td>\n",
       "      <td>-1.620347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  coefficient\n",
       "4788             waiting    -1.306888\n",
       "2664                mean    -1.320104\n",
       "5022     keyword_blazing    -1.353575\n",
       "1216                 don    -1.386778\n",
       "1897               heart    -1.408779\n",
       "5069  keyword_demolition    -1.416988\n",
       "308                  ass    -1.456028\n",
       "4578             trudeau    -1.456181\n",
       "2551                love    -1.521717\n",
       "5048    keyword_collapse    -1.620347"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_From the above top ranking positive and negative coefficients, we can see that most of them make sense._\n",
    "_Below are the coefficients for the three columns that I added. Two of them have high positive coefficients, but the feature capturing the news agencies actually has a negative coefficient which might probably be due to the fact that not all news are disaster related (or that I have not used the proper method to extract news related tweets!)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Resultant coefficient from added feature `Iran`:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>Iran</td>\n",
       "      <td>0.746721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  coefficient\n",
       "5002    Iran     0.746721"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.query(\"feature == 'Iran'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Resultant coefficient from added feature `hashtag`:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>0.3752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  coefficient\n",
       "5001  hashtag       0.3752"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.query(\"feature == 'hashtag'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Resultant coefficient from added feature `news_agency`:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>news_agency</td>\n",
       "      <td>-0.460113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  coefficient\n",
       "5000  news_agency    -0.460113"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.query(\"feature == 'news_agency'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 Test results\n",
    "rubric={reasoning:4}\n",
    "\n",
    "**Yout tasks**\n",
    "\n",
    "1. Report scores with your `scoring_metrics` on the test set. Use the model trained with all features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score for the test data is 0.7.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "test_score = f1_score(y_test_new, NLP_pipeline.predict(X_test_new))\n",
    "print(f\"The f1 score for the test data is {round(test_score, 2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for next exercises\n",
    "<hr>\n",
    "\n",
    "In the following exercises, we'll be using [`sklearn`'s boston housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html). \n",
    "\n",
    "_I just noticed the warning that this dataset has an ethical problem. We'll use this dataset for this assignment, as I didn't get a chance to replace it. But I encourage you to read why the dataset has an ethical problem and think about what would be the consequences of using this dataset._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artan\\miniconda3\\envs\\573\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_housing = load_boston()\n",
    "print(boston_housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "boston_df = pd.DataFrame(boston_housing.data, columns=boston_housing.feature_names)\n",
    "boston_df[\"target\"] = boston_housing.target\n",
    "train_df, test_df = train_test_split(boston_df, test_size=0.2, random_state=2)\n",
    "\n",
    "X_train, y_train = train_df.drop(columns=[\"target\"]), train_df[\"target\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"target\"]), test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Exercise 2: Change of basis <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "rubric={reasoning:1}\n",
    "\n",
    "The linear model is problematic when the target is a non-linear function of the input. With high dimensional data we cannot really know whether the target is a linear or non-linear function of the input. One way to examine this is by using _polynomial features_. Suppose you have a single feature $x_1$ in your original data, you can think of transforming the data into the following matrix $X_{poly}$ where each of its rows contains the values $(X_{i})^j$ for $j=0$ up to some maximum $degree$. E.g., \n",
    "\n",
    "$$\n",
    "X_{poly} = \\left[\\begin{array}{cccc}\n",
    "1 & x_1 & (x_1)^2 & (x_1)^3\\\\\n",
    "1 & x_2 & (x_2)^2 & (x_2)^3\\\\\n",
    "\\vdots\\\\\n",
    "1 & x_n & (x_n)^2 & (x_N)^3\\\\\n",
    "\\end{array}\n",
    "\\right],\n",
    "$$\n",
    "\n",
    "We can then fit a least squares model as if the above were our data set. You can think of this as \"changing the model by changing the data\" since we are still using a linear model but making the fit nonlinear by inventing new features. \n",
    "\n",
    "**Your tasks:**\n",
    "1. Is it possible to visualize the Boston housing data and examine whether a linear fit is good fit for this dataset or not? \n",
    "2. Carry out cross-validation using `DummyRegressor` on the train portion. \n",
    "3. Define a pipeline with `PolynomialFeatures` and `RidgeCV`. \n",
    "4. Examine the train and validation scores for three values for `degree` hyperparameter of `PolynomialFeatures`: 1, 2, and 3. Use either negative MAPE or `neg_root_mean_squared_error` for scoring. \n",
    "5. Which value of `degree` is giving you the best results? How many new features do you have with this degree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Feature importances and feature selection <a name=\"3\"></a>\n",
    "<hr>\n",
    "\n",
    "In this exercise we'll briefly explore feature importances, recursive feature elimination, adding polynomial features in a pipeline, and forward/backward selection. You could use the scoring method of your choice. The default $R^2$ is fine too.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 Adding random noise\n",
    "rubric={reasoning:4}\n",
    "\n",
    "The following code shows the coefficients learned by `RidgeCV` on the Boston housing dataset. It then adds a column of random noise to `X_train` and re-trains and examines the coefficients again. We see that the model has assigned a non-zero coefficient to the noise feature. But wait, we know this feature can't possibly be useful. \n",
    "\n",
    "**Yout taks:**\n",
    "\n",
    "1. Why is the importance of the random noise feature non-zero (and in fact larger than for some real features)? Maximum 2 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.107895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.039087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.020005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>3.138096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-15.339384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.640792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.008323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.367897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.321224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.011728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-1.021972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.011694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.560337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefficient\n",
       "CRIM       -0.107895\n",
       "ZN          0.039087\n",
       "INDUS      -0.020005\n",
       "CHAS        3.138096\n",
       "NOX       -15.339384\n",
       "RM          3.640792\n",
       "AGE         0.008323\n",
       "DIS        -1.367897\n",
       "RAD         0.321224\n",
       "TAX        -0.011728\n",
       "PTRATIO    -1.021972\n",
       "B           0.011694\n",
       "LSTAT      -0.560337"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv = RidgeCV()\n",
    "lrcv.fit(X_train, y_train)\n",
    "pd.DataFrame(data=lrcv.coef_, index=X_train.columns, columns=[\"coefficient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.18159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>6.376</td>\n",
       "      <td>54.3</td>\n",
       "      <td>4.5404</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>6.87</td>\n",
       "      <td>-0.494632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.08014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499</td>\n",
       "      <td>5.850</td>\n",
       "      <td>41.5</td>\n",
       "      <td>3.9342</td>\n",
       "      <td>5.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.77</td>\n",
       "      <td>0.843134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.01965</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385</td>\n",
       "      <td>6.230</td>\n",
       "      <td>31.5</td>\n",
       "      <td>9.0892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>341.60</td>\n",
       "      <td>12.93</td>\n",
       "      <td>1.466356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>-1.337690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.84054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.599</td>\n",
       "      <td>85.7</td>\n",
       "      <td>4.4546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>303.42</td>\n",
       "      <td>16.51</td>\n",
       "      <td>-0.426990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "321  0.18159   0.0   7.38   0.0  0.493  6.376  54.3  4.5404  5.0  287.0   \n",
       "37   0.08014   0.0   5.96   0.0  0.499  5.850  41.5  3.9342  5.0  279.0   \n",
       "286  0.01965  80.0   1.76   0.0  0.385  6.230  31.5  9.0892  1.0  241.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "25   0.84054   0.0   8.14   0.0  0.538  5.599  85.7  4.4546  4.0  307.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT     noise  \n",
       "321     19.6  396.90   6.87 -0.494632  \n",
       "37      19.2  396.90   8.77  0.843134  \n",
       "286     18.2  341.60  12.93  1.466356  \n",
       "2       17.8  392.83   4.03 -1.337690  \n",
       "25      21.0  303.42  16.51 -0.426990  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_noise = np.random.randn(X_train.shape[0], 1)\n",
    "X_train_noise = pd.concat(\n",
    "    (X_train, pd.DataFrame(random_noise, columns=[\"noise\"], index=X_train.index)),\n",
    "    axis=1,\n",
    ")\n",
    "X_train_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.107995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.039140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.017164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>3.154169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-15.359460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.645749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.008643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.366460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.321421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.011852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-1.015528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.011504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.562132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noise</th>\n",
       "      <td>-0.114962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefficient\n",
       "CRIM       -0.107995\n",
       "ZN          0.039140\n",
       "INDUS      -0.017164\n",
       "CHAS        3.154169\n",
       "NOX       -15.359460\n",
       "RM          3.645749\n",
       "AGE         0.008643\n",
       "DIS        -1.366460\n",
       "RAD         0.321421\n",
       "TAX        -0.011852\n",
       "PTRATIO    -1.015528\n",
       "B           0.011504\n",
       "LSTAT      -0.562132\n",
       "noise      -0.114962"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv = RidgeCV()\n",
    "lrcv.fit(X_train_noise, y_train)\n",
    "pd.DataFrame(data=lrcv.coef_, index=X_train_noise.columns, columns=[\"coefficient\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Column random noise is as the name suggests random values from a normal distribution with mean of 0 and standard deviation of 1. In fact, the values of this column are in the range of what other numeric columns would become after applying StandardScaler. The high value of coefficient is mainly due to confounding where some variations are not truly defined, and when we introduce the random feature with some values, it fills the gap by trying to make that noise variable relevant._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0    30\n",
       "98.2      4\n",
       "87.9      4\n",
       "97.9      4\n",
       "98.8      4\n",
       "         ..\n",
       "58.1      1\n",
       "49.0      1\n",
       "94.0      1\n",
       "45.4      1\n",
       "56.5      1\n",
       "Name: AGE, Length: 304, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_noise[\"AGE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 `RFECV` \n",
    "rubric={accuracy:4}\n",
    "\n",
    "In this exercise, you'll explore recursive feature elimination for feature selection. The code below defines a pipeline with feature selection incorporated in it. `RFECV` is used for feature selection in the pipeline; it uses cross-validation to decide how many features to select. The selected features are passed to `RidgeCV`, which has built-in cross-validation to tune the `alpha` hyperparameter.  \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out cross-validation using the pipeline below.  \n",
    "2. How many features have been selected by `RFECV`? You can access this information using the `n_features_` attribute of the `RFECV` step from the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rfe_ridgecv = make_pipeline(StandardScaler(), RFECV(Ridge(), cv=10), RidgeCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.188 (+/- 0.055)\n",
       "score_time     0.002 (+/- 0.001)\n",
       "test_score     0.704 (+/- 0.077)\n",
       "train_score    0.730 (+/- 0.017)\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_score = mean_std_cross_val_scores(\n",
    "    pipe_rfe_ridgecv, X_train, y_train, cv=5, return_train_score=True\n",
    ")\n",
    "rfe_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.704 (+/- 0.077)'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_score[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('rfecv', RFECV(cv=10, estimator=Ridge())),\n",
       "                ('ridgecv', RidgeCV(alphas=array([ 0.1,  1. , 10. ])))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rfe_ridgecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rfe_ridgecv.named_steps[\"rfecv\"].n_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: `PolynomialFeatures` + [`RFECV`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html)\n",
    "rubric={accuracy:4,reasoning:3}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Add one more step to the pipeline above, `PolynomialFeatures()`, for extracting polynomial features. \n",
    "2. Carry out cross-validation using the pipeline and report the mean validation scores. \n",
    "3. Are you getting better scores compared to 3.2? If yes, what might be the reason?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_pipe = make_pipeline(\n",
    "    StandardScaler(), PolynomialFeatures(degree=3), RFECV(Ridge(), cv=10), RidgeCV()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       23.586 (+/- 2.701)\n",
       "score_time      0.003 (+/- 0.001)\n",
       "test_score      0.845 (+/- 0.058)\n",
       "train_score     0.925 (+/- 0.017)\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_score = mean_std_cross_val_scores(\n",
    "    poly_pipe, X_train, y_train, cv=5, return_train_score=True\n",
    ")\n",
    "poly_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Our mean crossvalidation R2 score improved a lot from 0.7 to 0.84. This is mainly because of the higher number of features and the fact that some of these features have had a polynomial shape and once transformed to third degree polynomial, we have been able to fit them better in our regression model._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 3.4 \n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. How many total features there will be after applying `PolynomialFeatures` transformation? \n",
    "2. How many features have been selected by `RFECV`? \n",
    "3. Show the feature names of the features selected by `RFECV`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('polynomialfeatures', PolynomialFeatures(degree=3)),\n",
       "                ('rfecv', RFECV(cv=10, estimator=Ridge())),\n",
       "                ('ridgecv', RidgeCV(alphas=array([ 0.1,  1. , 10. ])))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_pipe.named_steps[\"rfecv\"].n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_pipe.named_steps[\"rfecv\"].n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x6', 'x7', 'x8', 'x35', 'x63', 'x64', 'x74', 'x76', 'x84', 'x89',\n",
       "       'x90', 'x95', 'x99', 'x134', 'x145', 'x167', 'x169', 'x187',\n",
       "       'x195', 'x251', 'x284', 'x336', 'x403', 'x420', 'x421', 'x423',\n",
       "       'x424', 'x453', 'x463', 'x484', 'x496', 'x505', 'x514', 'x515',\n",
       "       'x518', 'x524', 'x525', 'x541', 'x542', 'x544'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_pipe.named_steps[\"rfecv\"].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5: `PolynomialFeatures` + backward selection\n",
    "rubric={accuracy:4,reasoning:3}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Now define a pipeline with `StandardScaler()`, `PolynomialFeatures()`, and backward feature selection (`SequentialFeatureSelector` with `Ridge` and direction `backward`) and report cross-validation scores. \n",
    "2. Comment on the scores. \n",
    "3. What is the difference between RFE and backward selection? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_seq_pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(),\n",
    "    SequentialFeatureSelector(Ridge(), direction=\"backward\", n_jobs=-1),\n",
    "    RidgeCV(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_cross_val_scores(poly_seq_pipe, X_train, y_train, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_seq_pipe.named_steps['sequentialfeatureselector']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_2. The mean crossvalidation score from this pipeline with backward selection are less than the ones from RFECV._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_3. It takes a very longer time to fit a Sequential Feature Selector, and therefore, RFE could be more reliable with larger number of features. Sequential Feature Selector by default it's going to select $d/2$ features, but RFE could continue further and select fewer features which in turn would speed up the score time._  \n",
    "_In SFS we start with a set of all the features, sequentially find the one feature that has the least effect on the maximization of a cross-validation score and greedily remove features from the set. On the other hand, he goal of RFE is to select features by recursively considering smaller and smaller sets of features instead of just one feature removed by SFS. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute. Then, the least important features are removed from current set of features. That procedure is recursively repeated on the new set until the desired number of features to select is eventually reached._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLEASE READ BEFORE YOU SUBMIT:** \n",
    "\n",
    "When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from \"1\" will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Push all your work to your GitHub lab repository. \n",
    "4. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. \n",
    "5. Make sure that the plots and output are rendered properly in your submitted file. If the .ipynb file is too big and doesn't render on Gradescope, also upload a pdf or html in addition to the .ipynb so that the TAs can view your submission on Gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing the homework! This was a tricky one but I hope you had fun working on it. Well done :clap:! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"eva-well-done.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
